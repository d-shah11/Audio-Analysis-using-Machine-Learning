{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 2 - Regression Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the csv file from Project 1 which was created by exporting the dataset with one-hot encoding perfomed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv(\"data1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2017, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2017 entries, 0 to 2016\n",
      "Data columns (total 17 columns):\n",
      "id                  2017 non-null int64\n",
      "acousticness        2016 non-null float64\n",
      "danceability        2015 non-null float64\n",
      "duration_ms         2017 non-null int64\n",
      "energy              2017 non-null float64\n",
      "instrumentalness    1978 non-null float64\n",
      "key                 2015 non-null float64\n",
      "liveness            2016 non-null float64\n",
      "loudness            2017 non-null float64\n",
      "mode                1995 non-null float64\n",
      "speechiness         2017 non-null float64\n",
      "tempo               2016 non-null float64\n",
      "time_signature      1984 non-null float64\n",
      "valence             2016 non-null float64\n",
      "target              2017 non-null int64\n",
      "song_title          2017 non-null object\n",
      "artist              2017 non-null object\n",
      "dtypes: float64(12), int64(3), object(2)\n",
      "memory usage: 268.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>target</th>\n",
       "      <th>song_title</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.833</td>\n",
       "      <td>204600</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>-8.795</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4310</td>\n",
       "      <td>150.062</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.286</td>\n",
       "      <td>1</td>\n",
       "      <td>Mask Off</td>\n",
       "      <td>Future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1990</td>\n",
       "      <td>0.743</td>\n",
       "      <td>326933</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>-10.401</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>160.083</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.588</td>\n",
       "      <td>1</td>\n",
       "      <td>Redbone</td>\n",
       "      <td>Childish Gambino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.838</td>\n",
       "      <td>185707</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>-7.148</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2890</td>\n",
       "      <td>75.044</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.173</td>\n",
       "      <td>1</td>\n",
       "      <td>Xanny Family</td>\n",
       "      <td>Future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6040</td>\n",
       "      <td>0.494</td>\n",
       "      <td>199413</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>-15.236</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0261</td>\n",
       "      <td>86.468</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.230</td>\n",
       "      <td>1</td>\n",
       "      <td>Master Of None</td>\n",
       "      <td>Beach House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.678</td>\n",
       "      <td>392893</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>-11.648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>174.004</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.904</td>\n",
       "      <td>1</td>\n",
       "      <td>Parallel Lines</td>\n",
       "      <td>Junior Boys</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  acousticness  danceability  duration_ms  energy  instrumentalness  key  \\\n",
       "0   0        0.0102         0.833       204600   0.434          0.021900  2.0   \n",
       "1   1        0.1990         0.743       326933   0.359          0.006110  1.0   \n",
       "2   2        0.0344         0.838       185707   0.412          0.000234  2.0   \n",
       "3   3        0.6040         0.494       199413   0.338          0.510000  5.0   \n",
       "4   4        0.1800         0.678       392893   0.561          0.512000  5.0   \n",
       "\n",
       "   liveness  loudness  mode  speechiness    tempo  time_signature  valence  \\\n",
       "0    0.1650    -8.795   1.0       0.4310  150.062             4.0    0.286   \n",
       "1    0.1370   -10.401   1.0       0.0794  160.083             4.0    0.588   \n",
       "2    0.1590    -7.148   1.0       0.2890   75.044             4.0    0.173   \n",
       "3    0.0922   -15.236   1.0       0.0261   86.468             4.0    0.230   \n",
       "4    0.4390   -11.648   0.0       0.0694  174.004             4.0    0.904   \n",
       "\n",
       "   target      song_title            artist  \n",
       "0       1        Mask Off            Future  \n",
       "1       1         Redbone  Childish Gambino  \n",
       "2       1    Xanny Family            Future  \n",
       "3       1  Master Of None       Beach House  \n",
       "4       1  Parallel Lines       Junior Boys  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>target</th>\n",
       "      <th>song_title</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>2012</td>\n",
       "      <td>0.00106</td>\n",
       "      <td>0.584</td>\n",
       "      <td>274404</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>-3.501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>74.976</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0</td>\n",
       "      <td>Like A Bitch - Kill The Noise Remix</td>\n",
       "      <td>Kill The Noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>2013</td>\n",
       "      <td>0.08770</td>\n",
       "      <td>0.894</td>\n",
       "      <td>182182</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>-2.663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.131</td>\n",
       "      <td>110.041</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0</td>\n",
       "      <td>Candy</td>\n",
       "      <td>Dillon Francis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>2014</td>\n",
       "      <td>0.00857</td>\n",
       "      <td>0.637</td>\n",
       "      <td>207200</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>-2.467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.107</td>\n",
       "      <td>150.082</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0</td>\n",
       "      <td>Habit - Dack Janiels &amp; Wenzday Remix</td>\n",
       "      <td>Rain Man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>2015</td>\n",
       "      <td>0.00164</td>\n",
       "      <td>0.557</td>\n",
       "      <td>185600</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>-2.735</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133</td>\n",
       "      <td>150.011</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0</td>\n",
       "      <td>First Contact</td>\n",
       "      <td>Twin Moons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>2016</td>\n",
       "      <td>0.00281</td>\n",
       "      <td>0.446</td>\n",
       "      <td>204520</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.2180</td>\n",
       "      <td>-6.221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.141</td>\n",
       "      <td>190.013</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0</td>\n",
       "      <td>I Wanna Get Better</td>\n",
       "      <td>Bleachers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  acousticness  danceability  duration_ms  energy  instrumentalness  \\\n",
       "2012  2012       0.00106         0.584       274404   0.932          0.002690   \n",
       "2013  2013       0.08770         0.894       182182   0.892          0.001670   \n",
       "2014  2014       0.00857         0.637       207200   0.935          0.003990   \n",
       "2015  2015       0.00164         0.557       185600   0.992          0.677000   \n",
       "2016  2016       0.00281         0.446       204520   0.915          0.000039   \n",
       "\n",
       "      key  liveness  loudness  mode  speechiness    tempo  time_signature  \\\n",
       "2012  1.0    0.1290    -3.501   1.0        0.333   74.976             4.0   \n",
       "2013  1.0    0.0528    -2.663   1.0        0.131  110.041             4.0   \n",
       "2014  0.0    0.2140    -2.467   1.0        0.107  150.082             4.0   \n",
       "2015  1.0    0.0913    -2.735   1.0        0.133  150.011             4.0   \n",
       "2016  9.0    0.2180    -6.221   1.0        0.141  190.013             4.0   \n",
       "\n",
       "      valence  target                            song_title          artist  \n",
       "2012    0.211       0   Like A Bitch - Kill The Noise Remix  Kill The Noise  \n",
       "2013    0.867       0                                 Candy  Dillon Francis  \n",
       "2014    0.470       0  Habit - Dack Janiels & Wenzday Remix        Rain Man  \n",
       "2015    0.623       0                         First Contact      Twin Moons  \n",
       "2016    0.402       0                    I Wanna Get Better       Bleachers  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2.017000e+03</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>1978.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>1995.00000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>1984.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1008.000000</td>\n",
       "      <td>0.187678</td>\n",
       "      <td>0.618478</td>\n",
       "      <td>2.463062e+05</td>\n",
       "      <td>0.681577</td>\n",
       "      <td>0.135335</td>\n",
       "      <td>5.347891</td>\n",
       "      <td>0.190888</td>\n",
       "      <td>-7.085624</td>\n",
       "      <td>0.61604</td>\n",
       "      <td>0.092664</td>\n",
       "      <td>121.607967</td>\n",
       "      <td>3.967742</td>\n",
       "      <td>0.496683</td>\n",
       "      <td>0.505702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>582.402066</td>\n",
       "      <td>0.260024</td>\n",
       "      <td>0.161029</td>\n",
       "      <td>8.198181e+04</td>\n",
       "      <td>0.210273</td>\n",
       "      <td>0.274875</td>\n",
       "      <td>3.646163</td>\n",
       "      <td>0.155479</td>\n",
       "      <td>3.761684</td>\n",
       "      <td>0.48647</td>\n",
       "      <td>0.089931</td>\n",
       "      <td>26.691391</td>\n",
       "      <td>0.257940</td>\n",
       "      <td>0.247186</td>\n",
       "      <td>0.500091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.122000</td>\n",
       "      <td>1.604200e+04</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>-33.097000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>47.859000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>504.000000</td>\n",
       "      <td>0.009590</td>\n",
       "      <td>0.514000</td>\n",
       "      <td>2.000150e+05</td>\n",
       "      <td>0.563000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.092275</td>\n",
       "      <td>-8.394000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>100.164000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1008.000000</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>2.292610e+05</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.127000</td>\n",
       "      <td>-6.248000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>121.468000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.492000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1512.000000</td>\n",
       "      <td>0.265000</td>\n",
       "      <td>0.738000</td>\n",
       "      <td>2.703330e+05</td>\n",
       "      <td>0.846000</td>\n",
       "      <td>0.056600</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.247000</td>\n",
       "      <td>-4.746000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>137.860500</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.690250</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2016.000000</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>1.004627e+06</td>\n",
       "      <td>0.998000</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.969000</td>\n",
       "      <td>-0.307000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>219.331000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  acousticness  danceability   duration_ms       energy  \\\n",
       "count  2017.000000   2016.000000   2015.000000  2.017000e+03  2017.000000   \n",
       "mean   1008.000000      0.187678      0.618478  2.463062e+05     0.681577   \n",
       "std     582.402066      0.260024      0.161029  8.198181e+04     0.210273   \n",
       "min       0.000000      0.000003      0.122000  1.604200e+04     0.014800   \n",
       "25%     504.000000      0.009590      0.514000  2.000150e+05     0.563000   \n",
       "50%    1008.000000      0.063500      0.631000  2.292610e+05     0.715000   \n",
       "75%    1512.000000      0.265000      0.738000  2.703330e+05     0.846000   \n",
       "max    2016.000000      0.995000      0.984000  1.004627e+06     0.998000   \n",
       "\n",
       "       instrumentalness          key     liveness     loudness        mode  \\\n",
       "count       1978.000000  2015.000000  2016.000000  2017.000000  1995.00000   \n",
       "mean           0.135335     5.347891     0.190888    -7.085624     0.61604   \n",
       "std            0.274875     3.646163     0.155479     3.761684     0.48647   \n",
       "min            0.000000     0.000000     0.018800   -33.097000     0.00000   \n",
       "25%            0.000000     2.000000     0.092275    -8.394000     0.00000   \n",
       "50%            0.000093     6.000000     0.127000    -6.248000     1.00000   \n",
       "75%            0.056600     9.000000     0.247000    -4.746000     1.00000   \n",
       "max            0.976000    11.000000     0.969000    -0.307000     1.00000   \n",
       "\n",
       "       speechiness        tempo  time_signature      valence       target  \n",
       "count  2017.000000  2016.000000     1984.000000  2016.000000  2017.000000  \n",
       "mean      0.092664   121.607967        3.967742     0.496683     0.505702  \n",
       "std       0.089931    26.691391        0.257940     0.247186     0.500091  \n",
       "min       0.023100    47.859000        1.000000     0.034800     0.000000  \n",
       "25%       0.037500   100.164000        4.000000     0.295000     0.000000  \n",
       "50%       0.054900   121.468000        4.000000     0.492000     1.000000  \n",
       "75%       0.108000   137.860500        4.000000     0.690250     1.000000  \n",
       "max       0.816000   219.331000        5.000000     0.992000     1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    int64\n",
       "acousticness        float64\n",
       "danceability        float64\n",
       "duration_ms           int64\n",
       "energy              float64\n",
       "instrumentalness    float64\n",
       "key                 float64\n",
       "liveness            float64\n",
       "loudness            float64\n",
       "mode                float64\n",
       "speechiness         float64\n",
       "tempo               float64\n",
       "time_signature      float64\n",
       "valence             float64\n",
       "target                int64\n",
       "song_title           object\n",
       "artist               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for missing data and imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "acousticness         1\n",
       "danceability         2\n",
       "duration_ms          0\n",
       "energy               0\n",
       "instrumentalness    39\n",
       "key                  2\n",
       "liveness             1\n",
       "loudness             0\n",
       "mode                22\n",
       "speechiness          0\n",
       "tempo                1\n",
       "time_signature      33\n",
       "valence              1\n",
       "target               0\n",
       "song_title           0\n",
       "artist               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.187677678288691\n"
     ]
    }
   ],
   "source": [
    "print(df['acousticness'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['acousticness'].fillna(0.1876,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6184779156327529\n"
     ]
    }
   ],
   "source": [
    "print(df['danceability'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['danceability'].fillna(0.6185,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1353349620424672\n"
     ]
    }
   ],
   "source": [
    "print(df['instrumentalness'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['instrumentalness'].fillna(0.1353,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.347890818858561\n"
     ]
    }
   ],
   "source": [
    "print(df['key'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['key'].fillna(0.3479,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19088759920634923\n"
     ]
    }
   ],
   "source": [
    "print(df['liveness'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['liveness'].fillna(0.1909,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mode'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121.60796726190478\n"
     ]
    }
   ],
   "source": [
    "print(df['tempo'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tempo'].fillna(121.6080,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_signature'].fillna(3,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49668298611111134\n"
     ]
    }
   ],
   "source": [
    "print(df['valence'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['valence'].fillna(0.4969,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    int64\n",
       "acousticness        float64\n",
       "danceability        float64\n",
       "duration_ms           int64\n",
       "energy              float64\n",
       "instrumentalness    float64\n",
       "key                 float64\n",
       "liveness            float64\n",
       "loudness            float64\n",
       "mode                float64\n",
       "speechiness         float64\n",
       "tempo               float64\n",
       "time_signature      float64\n",
       "valence             float64\n",
       "target                int64\n",
       "song_title           object\n",
       "artist               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  0\n",
       "acousticness        0\n",
       "danceability        0\n",
       "duration_ms         0\n",
       "energy              0\n",
       "instrumentalness    0\n",
       "key                 0\n",
       "liveness            0\n",
       "loudness            0\n",
       "mode                0\n",
       "speechiness         0\n",
       "tempo               0\n",
       "time_signature      0\n",
       "valence             0\n",
       "target              0\n",
       "song_title          0\n",
       "artist              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['song_title','artist'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2017, 15)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('energy',axis = 1).values\n",
    "y = df.energy.values\n",
    "\n",
    "X_train_org, X_test_org, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1512, 14)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(505, 14)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_org.shape\n",
    "X_test_org.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1512,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(505,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scale = scaler.fit_transform(X_train_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scale = scaler.transform(X_test_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1512, 14)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scale.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Any Two Models with Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression with Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=Lasso(alpha=10, copy_X=True, fit_intercept=True,\n",
       "                                      max_iter=1000, normalize=False,\n",
       "                                      positive=False, precompute=False,\n",
       "                                      random_state=None, selection='cyclic',\n",
       "                                      tol=0.0001, warm_start=False),\n",
       "                 bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                 max_samples=100, n_estimators=500, n_jobs=None, oob_score=True,\n",
       "                 random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.026250281138522458"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.01278719026607511"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "lass = Lasso(alpha = 10)\n",
    "bag_clf = BaggingRegressor(lass,n_estimators=500, max_samples=100, bootstrap=True, random_state=0, oob_score=True)\n",
    "bag_clf.fit(X_train_org, y_train)\n",
    "y_pred = bag_clf.predict(X_test_org)\n",
    "\n",
    "bag_clf.score(X_train_org, y_train)\n",
    "bag_clf.score(X_test_org, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression with Bagging Summary:\n",
    "\n",
    "#### Train Score : 0.0263\n",
    "\n",
    "#### Test Score : 0.0128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Regression with Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=KNeighborsRegressor(algorithm='auto',\n",
       "                                                    leaf_size=30,\n",
       "                                                    metric='minkowski',\n",
       "                                                    metric_params=None,\n",
       "                                                    n_jobs=None, n_neighbors=10,\n",
       "                                                    p=2, weights='uniform'),\n",
       "                 bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                 max_samples=100, n_estimators=500, n_jobs=None, oob_score=True,\n",
       "                 random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.4941513795676028"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.4731040675252591"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors = 10)\n",
    "bag_clf = BaggingRegressor(knn,n_estimators=500, max_samples=100, bootstrap=True, random_state=0, oob_score=True)\n",
    "bag_clf.fit(X_train_scale, y_train)\n",
    "\n",
    "bag_clf.score(X_train_scale, y_train)\n",
    "bag_clf.score(X_test_scale, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Regression with Bagging Summary:\n",
    "\n",
    "#### Train Score : 0.4952\n",
    "\n",
    "#### Test Score : 0.4731"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Any Two Models with Pasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression with Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=Lasso(alpha=10, copy_X=True, fit_intercept=True,\n",
       "                                      max_iter=1000, normalize=False,\n",
       "                                      positive=False, precompute=False,\n",
       "                                      random_state=None, selection='cyclic',\n",
       "                                      tol=0.0001, warm_start=False),\n",
       "                 bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
       "                 max_samples=100, n_estimators=500, n_jobs=None,\n",
       "                 oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.02604699279137257"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.012695873289432003"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "lass = Lasso(alpha = 10)\n",
    "bag_clf = BaggingRegressor(lass,n_estimators=500, max_samples=100, bootstrap=False, random_state=0)\n",
    "bag_clf.fit(X_train_org, y_train)\n",
    "y_pred = bag_clf.predict(X_test_org)\n",
    "\n",
    "bag_clf.score(X_train_org, y_train)\n",
    "bag_clf.score(X_test_org, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression with Pasting Summary:\n",
    "\n",
    "#### Train Score : 0.0260\n",
    "\n",
    "#### Test Score : 0.0127"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Regression with Pasting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=KNeighborsRegressor(algorithm='auto',\n",
       "                                                    leaf_size=30,\n",
       "                                                    metric='minkowski',\n",
       "                                                    metric_params=None,\n",
       "                                                    n_jobs=None, n_neighbors=10,\n",
       "                                                    p=2, weights='uniform'),\n",
       "                 bootstrap=False, bootstrap_features=False, max_features=1.0,\n",
       "                 max_samples=100, n_estimators=500, n_jobs=None,\n",
       "                 oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.49435491844351365"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.4744172517512019"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingRegressor(knn,n_estimators=500, max_samples=100, bootstrap=False, random_state=0)\n",
    "bag_clf.fit(X_train_scale, y_train)\n",
    "\n",
    "bag_clf.score(X_train_scale, y_train)\n",
    "bag_clf.score(X_test_scale, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Regression with Pasting Summary:\n",
    "\n",
    "#### Train Score : 0.4944\n",
    "\n",
    "#### Test Score : 0.4744"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Any Two Models with AdaBoost Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Regression with AdaBoosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "             estimator=AdaBoostRegressor(base_estimator=KNeighborsRegressor(algorithm='auto',\n",
       "                                                                            leaf_size=30,\n",
       "                                                                            metric='minkowski',\n",
       "                                                                            metric_params=None,\n",
       "                                                                            n_jobs=None,\n",
       "                                                                            n_neighbors=10,\n",
       "                                                                            p=2,\n",
       "                                                                            weights='uniform'),\n",
       "                                         learning_rate=1.0, loss='linear',\n",
       "                                         n_estimators=100, random_state=None),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.1, 0.5, 1.0]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "param_grid = {'learning_rate': [0.1,0.5,1.0]}\n",
    "ada_clf = AdaBoostRegressor(knn,n_estimators=100)\n",
    "GridSearch_dtclf = GridSearchCV(ada_clf, param_grid,cv=4,return_train_score=True,n_jobs= -1)\n",
    "\n",
    "GridSearch_dtclf.fit(X_train_scale, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6463954524078758"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GridSearch_dtclf.best_params_\n",
    "GridSearch_dtclf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.941914</td>\n",
       "      <td>1.197473</td>\n",
       "      <td>4.558397</td>\n",
       "      <td>0.507606</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'learning_rate': 0.1}</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.629662</td>\n",
       "      <td>0.610999</td>\n",
       "      <td>0.682555</td>\n",
       "      <td>0.646395</td>\n",
       "      <td>0.027818</td>\n",
       "      <td>1</td>\n",
       "      <td>0.716094</td>\n",
       "      <td>0.715087</td>\n",
       "      <td>0.724796</td>\n",
       "      <td>0.718920</td>\n",
       "      <td>0.718724</td>\n",
       "      <td>0.003777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.255297</td>\n",
       "      <td>1.029731</td>\n",
       "      <td>4.343195</td>\n",
       "      <td>0.536311</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'learning_rate': 0.5}</td>\n",
       "      <td>0.608042</td>\n",
       "      <td>0.599223</td>\n",
       "      <td>0.572941</td>\n",
       "      <td>0.638718</td>\n",
       "      <td>0.604731</td>\n",
       "      <td>0.023489</td>\n",
       "      <td>2</td>\n",
       "      <td>0.710476</td>\n",
       "      <td>0.703588</td>\n",
       "      <td>0.711082</td>\n",
       "      <td>0.712052</td>\n",
       "      <td>0.709299</td>\n",
       "      <td>0.003345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.176421</td>\n",
       "      <td>0.145644</td>\n",
       "      <td>3.610247</td>\n",
       "      <td>0.031988</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 1.0}</td>\n",
       "      <td>0.574766</td>\n",
       "      <td>0.566201</td>\n",
       "      <td>0.553716</td>\n",
       "      <td>0.578739</td>\n",
       "      <td>0.568355</td>\n",
       "      <td>0.009590</td>\n",
       "      <td>3</td>\n",
       "      <td>0.704660</td>\n",
       "      <td>0.694765</td>\n",
       "      <td>0.699175</td>\n",
       "      <td>0.706469</td>\n",
       "      <td>0.701267</td>\n",
       "      <td>0.004616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      12.941914      1.197473         4.558397        0.507606   \n",
       "1      13.255297      1.029731         4.343195        0.536311   \n",
       "2      11.176421      0.145644         3.610247        0.031988   \n",
       "\n",
       "  param_learning_rate                  params  split0_test_score  \\\n",
       "0                 0.1  {'learning_rate': 0.1}           0.662366   \n",
       "1                 0.5  {'learning_rate': 0.5}           0.608042   \n",
       "2                   1  {'learning_rate': 1.0}           0.574766   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0           0.629662           0.610999           0.682555         0.646395   \n",
       "1           0.599223           0.572941           0.638718         0.604731   \n",
       "2           0.566201           0.553716           0.578739         0.568355   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.027818                1            0.716094            0.715087   \n",
       "1        0.023489                2            0.710476            0.703588   \n",
       "2        0.009590                3            0.704660            0.694765   \n",
       "\n",
       "   split2_train_score  split3_train_score  mean_train_score  std_train_score  \n",
       "0            0.724796            0.718920          0.718724         0.003777  \n",
       "1            0.711082            0.712052          0.709299         0.003345  \n",
       "2            0.699175            0.706469          0.701267         0.004616  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lasso_ada= pd.DataFrame(GridSearch_dtclf.cv_results_)\n",
    "result_lasso_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=KNeighborsRegressor(algorithm='auto',\n",
       "                                                     leaf_size=30,\n",
       "                                                     metric='minkowski',\n",
       "                                                     metric_params=None,\n",
       "                                                     n_jobs=None,\n",
       "                                                     n_neighbors=10, p=2,\n",
       "                                                     weights='uniform'),\n",
       "                  learning_rate=0.1, loss='linear', n_estimators=100,\n",
       "                  random_state=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "ada_clf = AdaBoostRegressor(knn,n_estimators=100,learning_rate = 0.1)\n",
    "ada_clf.fit(X_train_scale, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7304639897088798"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6206149033426653"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf.score(X_train_scale, y_train)\n",
    "ada_clf.score(X_test_scale, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Regression with AdaBoosting Summary:\n",
    "\n",
    "#### Train Score: 0.7309\n",
    "\n",
    "#### Test Score : 0.6208"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression with AdaBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=Lasso(alpha=10, copy_X=True,\n",
       "                                       fit_intercept=True, max_iter=1000,\n",
       "                                       normalize=False, positive=False,\n",
       "                                       precompute=False, random_state=None,\n",
       "                                       selection='cyclic', tol=0.0001,\n",
       "                                       warm_start=False),\n",
       "                  learning_rate=0.25, loss='linear', n_estimators=200,\n",
       "                  random_state=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.009918388730553174"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0006879092368200501"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf = AdaBoostRegressor(lass, n_estimators=200, learning_rate=0.25, random_state=0)\n",
    "ada_clf.fit(X_train_org, y_train)\n",
    "ada_clf.score(X_train_org, y_train)\n",
    "ada_clf.score(X_test_org, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression with AdaBoosting Summary:\n",
    "\n",
    "#### Train Score : 0.0010\n",
    "\n",
    "#### Test Score : 0.0007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=1.0, loss='ls', max_depth=2,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=3,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=42, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6640871021163337"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5962221753355985"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0, random_state=42)\n",
    "gbrt.fit(X_train_org, y_train)\n",
    "gbrt.score(X_train_org, y_train)\n",
    "gbrt.score(X_test_org, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Summary:\n",
    "\n",
    "#### Train Score : 0.6641\n",
    "\n",
    "#### Test Score : 0.5962"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16659688, 0.14877009, 0.10295812, 0.08532472, 0.07466868,\n",
       "       0.07290634, 0.06676584, 0.06103421, 0.05702312, 0.0507846 ,\n",
       "       0.04395671, 0.03402998, 0.0257594 , 0.00942131])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train_scale)\n",
    "\n",
    "pca.explained_variance_ratio_\n",
    "\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= 0.95) + 1\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9648192893827919"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 12)\n",
    "X_train_pca = pca.fit_transform(X_train_scale)\n",
    "np.sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pca.fit_transform(X_train_scale)\n",
    "X_test_pca = pca.transform(X_test_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1512, 12)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6, error_score='raise-deprecating',\n",
       "             estimator=LinearRegression(copy_X=True, fit_intercept=True,\n",
       "                                        n_jobs=None, normalize=False),\n",
       "             iid='warn', n_jobs=None, param_grid={'normalize': [True, False]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'normalize': True}\n",
      "Best cross-validation score: 0.6896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "model = LinearRegression()\n",
    "parameters = {'normalize':[True,False]}\n",
    "grid_search_lr = GridSearchCV(model,parameters, cv=6, return_train_score=True)\n",
    "grid_search_lr.fit(X_train_pca, y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search_lr.best_params_))\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid_search_lr.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_normalize</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>True</td>\n",
       "      <td>{'normalize': True}</td>\n",
       "      <td>0.661082</td>\n",
       "      <td>0.71059</td>\n",
       "      <td>0.696742</td>\n",
       "      <td>0.684643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022738</td>\n",
       "      <td>1</td>\n",
       "      <td>0.701258</td>\n",
       "      <td>0.691337</td>\n",
       "      <td>0.694974</td>\n",
       "      <td>0.697246</td>\n",
       "      <td>0.689739</td>\n",
       "      <td>0.701158</td>\n",
       "      <td>0.695952</td>\n",
       "      <td>0.004431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>False</td>\n",
       "      <td>{'normalize': False}</td>\n",
       "      <td>0.661082</td>\n",
       "      <td>0.71059</td>\n",
       "      <td>0.696742</td>\n",
       "      <td>0.684643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022738</td>\n",
       "      <td>1</td>\n",
       "      <td>0.701258</td>\n",
       "      <td>0.691337</td>\n",
       "      <td>0.694974</td>\n",
       "      <td>0.697246</td>\n",
       "      <td>0.689739</td>\n",
       "      <td>0.701158</td>\n",
       "      <td>0.695952</td>\n",
       "      <td>0.004431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.001995      0.002701         0.000332        0.000470   \n",
       "1       0.000666      0.000471         0.000156        0.000349   \n",
       "\n",
       "  param_normalize                params  split0_test_score  split1_test_score  \\\n",
       "0            True   {'normalize': True}           0.661082            0.71059   \n",
       "1           False  {'normalize': False}           0.661082            0.71059   \n",
       "\n",
       "   split2_test_score  split3_test_score  ...  std_test_score  rank_test_score  \\\n",
       "0           0.696742           0.684643  ...        0.022738                1   \n",
       "1           0.696742           0.684643  ...        0.022738                1   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.701258            0.691337            0.694974   \n",
       "1            0.701258            0.691337            0.694974   \n",
       "\n",
       "   split3_train_score  split4_train_score  split5_train_score  \\\n",
       "0            0.697246            0.689739            0.701158   \n",
       "1            0.697246            0.689739            0.701158   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.695952         0.004431  \n",
       "1          0.695952         0.004431  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_search_lr.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6955555494598618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6804722704510557"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg = LinearRegression(normalize = True)\n",
    "lreg.fit(X_train_pca, y_train)\n",
    "print(lreg.score(X_train_pca, y_train))\n",
    "lr_test_score = lreg.score(X_test_pca, y_test)\n",
    "lr_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[0.66108153 0.71059016 0.69674248 0.68464346 0.72205373 0.66277875]\n",
      "0.6896483521426454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "  \n",
    "kfold = KFold(n_splits=6)\n",
    "print(\"Cross-validation scores:\\n{}\".format(cross_val_score(lreg , X_train_pca, y_train, cv=kfold)))\n",
    "scores = cross_val_score(lreg , X_train_pca, y_train, cv=kfold)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee50877ba8>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1ee50877d68>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'sqft_living')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PLOT\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#X_train_array = X_train_org.to_numpy()\n",
    "\n",
    "#X_train_rm = X_train_array[:,2].reshape(-1,1)\n",
    "\n",
    "X_train_rm = X_train_org[:,2].reshape(-1,1)\n",
    "lreg.fit(X_train_rm, y_train)\n",
    "y_predict = lreg.predict(X_train_rm)\n",
    "\n",
    "plt.plot(X_train_rm, y_predict, c = 'r')\n",
    "plt.scatter(X_train_rm,y_train)\n",
    "plt.xlabel('sqft_living')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Summary:\n",
    "\n",
    "#### Train Score: 0.6956\n",
    "\n",
    "#### Test Score: 0.6805\n",
    "\n",
    "#### Best Parameter: {'normalize' : True}\n",
    "\n",
    "#### Best Cross - Validation Score: 0.6896"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parms_knn = {'n_neighbors':[1,5,10,15,20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6, error_score='raise-deprecating',\n",
       "             estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30,\n",
       "                                           metric='minkowski',\n",
       "                                           metric_params=None, n_jobs=None,\n",
       "                                           n_neighbors=5, p=2,\n",
       "                                           weights='uniform'),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'n_neighbors': [1, 5, 10, 15, 20]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "grid_search_knn = GridSearchCV(knn, grid_parms_knn,cv=6,return_train_score=True,n_jobs= -1)\n",
    "grid_search_knn.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_neighbors': 10}\n",
      "Best cross-validation score: 0.6258\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002161</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.015616</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_neighbors': 1}</td>\n",
       "      <td>0.421427</td>\n",
       "      <td>0.551229</td>\n",
       "      <td>0.223191</td>\n",
       "      <td>0.391405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096931</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003296</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.022123</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.598767</td>\n",
       "      <td>0.669548</td>\n",
       "      <td>0.571707</td>\n",
       "      <td>0.595195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032168</td>\n",
       "      <td>4</td>\n",
       "      <td>0.731695</td>\n",
       "      <td>0.716498</td>\n",
       "      <td>0.730200</td>\n",
       "      <td>0.737697</td>\n",
       "      <td>0.729229</td>\n",
       "      <td>0.738841</td>\n",
       "      <td>0.730693</td>\n",
       "      <td>0.007307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.017633</td>\n",
       "      <td>0.002982</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_neighbors': 10}</td>\n",
       "      <td>0.605140</td>\n",
       "      <td>0.676069</td>\n",
       "      <td>0.611738</td>\n",
       "      <td>0.594942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029701</td>\n",
       "      <td>1</td>\n",
       "      <td>0.691941</td>\n",
       "      <td>0.674760</td>\n",
       "      <td>0.691221</td>\n",
       "      <td>0.693407</td>\n",
       "      <td>0.684805</td>\n",
       "      <td>0.693201</td>\n",
       "      <td>0.688223</td>\n",
       "      <td>0.006676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002614</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.023276</td>\n",
       "      <td>0.004524</td>\n",
       "      <td>15</td>\n",
       "      <td>{'n_neighbors': 15}</td>\n",
       "      <td>0.617311</td>\n",
       "      <td>0.660565</td>\n",
       "      <td>0.621157</td>\n",
       "      <td>0.576819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028162</td>\n",
       "      <td>2</td>\n",
       "      <td>0.670320</td>\n",
       "      <td>0.660114</td>\n",
       "      <td>0.664472</td>\n",
       "      <td>0.668015</td>\n",
       "      <td>0.661883</td>\n",
       "      <td>0.671819</td>\n",
       "      <td>0.666104</td>\n",
       "      <td>0.004290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002201</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.021127</td>\n",
       "      <td>0.004243</td>\n",
       "      <td>20</td>\n",
       "      <td>{'n_neighbors': 20}</td>\n",
       "      <td>0.617206</td>\n",
       "      <td>0.647748</td>\n",
       "      <td>0.620677</td>\n",
       "      <td>0.573904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025157</td>\n",
       "      <td>3</td>\n",
       "      <td>0.651788</td>\n",
       "      <td>0.642357</td>\n",
       "      <td>0.647282</td>\n",
       "      <td>0.655603</td>\n",
       "      <td>0.642972</td>\n",
       "      <td>0.655733</td>\n",
       "      <td>0.649289</td>\n",
       "      <td>0.005472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.002161      0.000373         0.015616        0.001091   \n",
       "1       0.003296      0.001285         0.022123        0.002130   \n",
       "2       0.001962      0.000041         0.017633        0.002982   \n",
       "3       0.002614      0.000448         0.023276        0.004524   \n",
       "4       0.002201      0.000805         0.021127        0.004243   \n",
       "\n",
       "  param_n_neighbors               params  split0_test_score  \\\n",
       "0                 1   {'n_neighbors': 1}           0.421427   \n",
       "1                 5   {'n_neighbors': 5}           0.598767   \n",
       "2                10  {'n_neighbors': 10}           0.605140   \n",
       "3                15  {'n_neighbors': 15}           0.617311   \n",
       "4                20  {'n_neighbors': 20}           0.617206   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  ...  \\\n",
       "0           0.551229           0.223191           0.391405  ...   \n",
       "1           0.669548           0.571707           0.595195  ...   \n",
       "2           0.676069           0.611738           0.594942  ...   \n",
       "3           0.660565           0.621157           0.576819  ...   \n",
       "4           0.647748           0.620677           0.573904  ...   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.096931                5            1.000000            1.000000   \n",
       "1        0.032168                4            0.731695            0.716498   \n",
       "2        0.029701                1            0.691941            0.674760   \n",
       "3        0.028162                2            0.670320            0.660114   \n",
       "4        0.025157                3            0.651788            0.642357   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            1.000000            1.000000            1.000000   \n",
       "1            0.730200            0.737697            0.729229   \n",
       "2            0.691221            0.693407            0.684805   \n",
       "3            0.664472            0.668015            0.661883   \n",
       "4            0.647282            0.655603            0.642972   \n",
       "\n",
       "   split5_train_score  mean_train_score  std_train_score  \n",
       "0            1.000000          1.000000         0.000000  \n",
       "1            0.738841          0.730693         0.007307  \n",
       "2            0.693201          0.688223         0.006676  \n",
       "3            0.671819          0.666104         0.004290  \n",
       "4            0.655733          0.649289         0.005472  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search_knn.best_params_))\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid_search_knn.best_score_))\n",
    "pd.DataFrame(grid_search_knn.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                    weights='uniform')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6913540757064955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6045806851814914"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors = 10)\n",
    "knn.fit(X_train_pca, y_train)\n",
    "print(knn.score(X_train_pca, y_train))\n",
    "knn_test_score_ = knn.score(X_test_pca, y_test)\n",
    "knn_test_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[0.60514031 0.67606942 0.61173799 0.59494206 0.65667458 0.61044463]\n",
      "0.625834831477951\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "  \n",
    "kfold = KFold(n_splits=6)\n",
    "print(\"Cross-validation scores:\\n{}\".format(cross_val_score(knn , X_train_pca, y_train, cv=kfold)))\n",
    "scores = cross_val_score(knn , X_train_pca, y_train, cv=kfold)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                    weights='uniform')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee50960160>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1ee509606d8>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'sqft_living')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_b = X_train_org[:50,2].reshape(-1,1)\n",
    "y_b = y_train[:50]\n",
    "\n",
    "knn_reg = KNeighborsRegressor(10)\n",
    "knn_reg.fit(X_b, y_b)\n",
    "\n",
    "X_new=np.linspace(X_b.min(), X_b.max(), 50).reshape(50, 1)\n",
    "y_predict = knn_reg.predict(X_new)\n",
    "\n",
    "plt.plot(X_new, y_predict, c = 'r')\n",
    "plt.scatter(X_b, y_b)\n",
    "plt.xlabel('sqft_living')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Regression Summary:\n",
    "\n",
    "#### Train Score: 0.6914\n",
    "\n",
    "#### Test Score: 0.6046\n",
    "\n",
    "#### Best parameters: {'n_neighbors' : 10}\n",
    "\n",
    "#### Best Cross - Validation Score: 0.6258"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parms_ridge = {'alpha': [0.01, 0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                             max_iter=None, normalize=False, random_state=None,\n",
       "                             solver='auto', tol=0.001),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'alpha': [0.01, 0.1, 1, 10, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 10}\n",
      "Best cross-validation score: 0.6885\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge()\n",
    "grid_search_ridge = GridSearchCV(estimator = ridge,param_grid = grid_parms_ridge,return_train_score=True,n_jobs= -1,cv=5)\n",
    "grid_search_ridge.fit(X_train_pca, y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search_ridge.best_params_))\n",
    "\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid_search_ridge.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None, normalize=False,\n",
       "      random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6955553286395487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6804586139054339"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge(alpha = 1)\n",
    "ridge.fit(X_train_pca, y_train)\n",
    "print(ridge.score(X_train_pca, y_train))\n",
    "ridge_test_score_ = ridge.score(X_test_pca, y_test)\n",
    "ridge_test_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[0.66115431 0.71057115 0.69672738 0.68461466 0.72205333 0.66280047]\n",
      "0.6896535501606035\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "  \n",
    "kfold = KFold(n_splits=6)\n",
    "print(\"Cross-validation scores:\\n{}\".format(cross_val_score(ridge , X_train_pca, y_train, cv=kfold)))\n",
    "scores = cross_val_score(ridge , X_train_pca, y_train, cv=kfold)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012731</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.647629</td>\n",
       "      <td>0.717941</td>\n",
       "      <td>0.682919</td>\n",
       "      <td>0.699654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688448</td>\n",
       "      <td>0.023364</td>\n",
       "      <td>4</td>\n",
       "      <td>0.705899</td>\n",
       "      <td>0.688213</td>\n",
       "      <td>0.697795</td>\n",
       "      <td>0.693616</td>\n",
       "      <td>0.695159</td>\n",
       "      <td>0.696137</td>\n",
       "      <td>0.005799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005174</td>\n",
       "      <td>0.003452</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.647634</td>\n",
       "      <td>0.717941</td>\n",
       "      <td>0.682914</td>\n",
       "      <td>0.699656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688449</td>\n",
       "      <td>0.023362</td>\n",
       "      <td>3</td>\n",
       "      <td>0.705899</td>\n",
       "      <td>0.688213</td>\n",
       "      <td>0.697795</td>\n",
       "      <td>0.693616</td>\n",
       "      <td>0.695159</td>\n",
       "      <td>0.696137</td>\n",
       "      <td>0.005799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>0.647687</td>\n",
       "      <td>0.717943</td>\n",
       "      <td>0.682866</td>\n",
       "      <td>0.699677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688453</td>\n",
       "      <td>0.023348</td>\n",
       "      <td>2</td>\n",
       "      <td>0.705898</td>\n",
       "      <td>0.688213</td>\n",
       "      <td>0.697795</td>\n",
       "      <td>0.693616</td>\n",
       "      <td>0.695159</td>\n",
       "      <td>0.696136</td>\n",
       "      <td>0.005799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "      <td>0.648176</td>\n",
       "      <td>0.717929</td>\n",
       "      <td>0.682366</td>\n",
       "      <td>0.699848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688463</td>\n",
       "      <td>0.023211</td>\n",
       "      <td>1</td>\n",
       "      <td>0.705864</td>\n",
       "      <td>0.688178</td>\n",
       "      <td>0.697764</td>\n",
       "      <td>0.693581</td>\n",
       "      <td>0.695127</td>\n",
       "      <td>0.696103</td>\n",
       "      <td>0.005799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>100</td>\n",
       "      <td>{'alpha': 100}</td>\n",
       "      <td>0.649827</td>\n",
       "      <td>0.715469</td>\n",
       "      <td>0.675894</td>\n",
       "      <td>0.697946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686028</td>\n",
       "      <td>0.022140</td>\n",
       "      <td>5</td>\n",
       "      <td>0.703014</td>\n",
       "      <td>0.685287</td>\n",
       "      <td>0.695220</td>\n",
       "      <td>0.690714</td>\n",
       "      <td>0.692441</td>\n",
       "      <td>0.693335</td>\n",
       "      <td>0.005825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.012731      0.001383         0.000983        0.000135        0.01   \n",
       "1       0.005174      0.003452         0.000723        0.000365         0.1   \n",
       "2       0.000798      0.000399         0.000676        0.000570           1   \n",
       "3       0.000707      0.000737         0.000610        0.000499          10   \n",
       "4       0.000786      0.000394         0.000627        0.000515         100   \n",
       "\n",
       "            params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'alpha': 0.01}           0.647629           0.717941           0.682919   \n",
       "1   {'alpha': 0.1}           0.647634           0.717941           0.682914   \n",
       "2     {'alpha': 1}           0.647687           0.717943           0.682866   \n",
       "3    {'alpha': 10}           0.648176           0.717929           0.682366   \n",
       "4   {'alpha': 100}           0.649827           0.715469           0.675894   \n",
       "\n",
       "   split3_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           0.699654  ...         0.688448        0.023364                4   \n",
       "1           0.699656  ...         0.688449        0.023362                3   \n",
       "2           0.699677  ...         0.688453        0.023348                2   \n",
       "3           0.699848  ...         0.688463        0.023211                1   \n",
       "4           0.697946  ...         0.686028        0.022140                5   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.705899            0.688213            0.697795   \n",
       "1            0.705899            0.688213            0.697795   \n",
       "2            0.705898            0.688213            0.697795   \n",
       "3            0.705864            0.688178            0.697764   \n",
       "4            0.703014            0.685287            0.695220   \n",
       "\n",
       "   split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.693616            0.695159          0.696137         0.005799  \n",
       "1            0.693616            0.695159          0.696137         0.005799  \n",
       "2            0.693616            0.695159          0.696136         0.005799  \n",
       "3            0.693581            0.695127          0.696103         0.005799  \n",
       "4            0.690714            0.692441          0.693335         0.005825  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_ridge = pd.DataFrame(grid_search_ridge.cv_results_)\n",
    "result_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee509d53c8>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee509d5780>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x1ee509197b8>,\n",
       "  <matplotlib.axis.XTick at 0x1ee5098f0f0>,\n",
       "  <matplotlib.axis.XTick at 0x1ee5098fe48>,\n",
       "  <matplotlib.axis.XTick at 0x1ee509d5e10>,\n",
       "  <matplotlib.axis.XTick at 0x1ee509e2320>],\n",
       " <a list of 5 Text xticklabel objects>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee509e26a0>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee509e2be0>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ee509e2f98>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Alpha')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(result_ridge.shape[0]), result_ridge['mean_train_score'], label = 'mean train score')\n",
    "plt.plot(range(result_ridge.shape[0]), result_ridge['mean_test_score'], label = 'mean test score')\n",
    "plt.xticks(range(result_ridge.shape[0]), result_ridge['param_alpha'], rotation = 90)\n",
    "plt.plot([grid_search_ridge.best_index_], result_ridge['mean_train_score'][grid_search_ridge.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.plot([grid_search_ridge.best_index_], result_ridge['mean_test_score'][grid_search_ridge.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('Alpha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression Summary:\n",
    "\n",
    "#### Train Score: 0.6956\n",
    "\n",
    "#### Test Score: 0.6805\n",
    "\n",
    "#### Best Parameters: {'alpha' : 10}\n",
    "\n",
    "#### Best Cross - Validation Score: 0.6885"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parms_lasso = {'alpha': [0.01, 0.1, 1, 10,100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                             max_iter=1000, normalize=False, positive=False,\n",
       "                             precompute=False, random_state=None,\n",
       "                             selection='cyclic', tol=0.0001, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'alpha': [0.01, 0.1, 1, 10, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 0.01}\n",
      "Best cross-validation score: 0.6686\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "grid_search_lasso = GridSearchCV(estimator = lasso,param_grid = grid_parms_lasso,return_train_score=True,n_jobs=-1,cv=5)\n",
    "grid_search_lasso.fit(X_train_pca, y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search_lasso.best_params_))\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid_search_lasso.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=10, copy_X=True, fit_intercept=True, max_iter=1000, normalize=False,\n",
       "      positive=False, precompute=False, random_state=None, selection='cyclic',\n",
       "      tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2.8005758561100436e-06"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "las = Lasso(alpha = 10)\n",
    "las.fit(X_train_pca, y_train)\n",
    "print(las.score(X_train_pca, y_train))\n",
    "las_test_score_ = las.score(X_test_pca, y_test)\n",
    "las_test_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[-1.95811601e-03 -9.56784282e-05 -1.26085227e-04 -8.69436647e-04\n",
      " -3.47135988e-03 -2.09627356e-04]\n",
      "-0.0011217172578971146\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "  \n",
    "kfold = KFold(n_splits=6)\n",
    "print(\"Cross-validation scores:\\n{}\".format(cross_val_score(lass , X_train_pca, y_train, cv=kfold)))\n",
    "scores = cross_val_score(lass , X_train_pca, y_train, cv=kfold)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.641841</td>\n",
       "      <td>0.697043</td>\n",
       "      <td>0.654978</td>\n",
       "      <td>0.682145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668594</td>\n",
       "      <td>0.019490</td>\n",
       "      <td>1</td>\n",
       "      <td>0.684492</td>\n",
       "      <td>0.665666</td>\n",
       "      <td>0.676166</td>\n",
       "      <td>0.672546</td>\n",
       "      <td>0.672109</td>\n",
       "      <td>0.674196</td>\n",
       "      <td>0.006160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.237759</td>\n",
       "      <td>0.282439</td>\n",
       "      <td>0.252224</td>\n",
       "      <td>0.239664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257819</td>\n",
       "      <td>0.018644</td>\n",
       "      <td>2</td>\n",
       "      <td>0.279529</td>\n",
       "      <td>0.228918</td>\n",
       "      <td>0.271879</td>\n",
       "      <td>0.276914</td>\n",
       "      <td>0.253888</td>\n",
       "      <td>0.262226</td>\n",
       "      <td>0.018906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>-0.002549</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>-0.000992</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000864</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "      <td>-0.002549</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>-0.000992</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000864</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>100</td>\n",
       "      <td>{'alpha': 100}</td>\n",
       "      <td>-0.002549</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>-0.000992</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000864</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.001389      0.000533         0.000614        0.000501        0.01   \n",
       "1       0.001371      0.000441         0.000626        0.000458         0.1   \n",
       "2       0.001123      0.000380         0.000739        0.000598           1   \n",
       "3       0.000728      0.000383         0.000715        0.000475          10   \n",
       "4       0.000790      0.000396         0.000704        0.000401         100   \n",
       "\n",
       "            params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'alpha': 0.01}           0.641841           0.697043           0.654978   \n",
       "1   {'alpha': 0.1}           0.237759           0.282439           0.252224   \n",
       "2     {'alpha': 1}          -0.002549          -0.000035          -0.000146   \n",
       "3    {'alpha': 10}          -0.002549          -0.000035          -0.000146   \n",
       "4   {'alpha': 100}          -0.002549          -0.000035          -0.000146   \n",
       "\n",
       "   split3_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           0.682145  ...         0.668594        0.019490                1   \n",
       "1           0.239664  ...         0.257819        0.018644                2   \n",
       "2          -0.000992  ...        -0.000864        0.000910                3   \n",
       "3          -0.000992  ...        -0.000864        0.000910                3   \n",
       "4          -0.000992  ...        -0.000864        0.000910                3   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.684492            0.665666            0.676166   \n",
       "1            0.279529            0.228918            0.271879   \n",
       "2            0.000000            0.000000            0.000000   \n",
       "3            0.000000            0.000000            0.000000   \n",
       "4            0.000000            0.000000            0.000000   \n",
       "\n",
       "   split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.672546            0.672109          0.674196         0.006160  \n",
       "1            0.276914            0.253888          0.262226         0.018906  \n",
       "2            0.000000            0.000000          0.000000         0.000000  \n",
       "3            0.000000            0.000000          0.000000         0.000000  \n",
       "4            0.000000            0.000000          0.000000         0.000000  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lasso = pd.DataFrame(grid_search_lasso.cv_results_)\n",
    "result_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee50a507b8>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee50979ef0>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x1ee50a37e48>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50a377b8>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50a374e0>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50a601d0>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50a606d8>],\n",
       " <a list of 5 Text xticklabel objects>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee50a50e80>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee50a604a8>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ee50a50fd0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Alpha')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEUCAYAAAA7l80JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3hUZdrH8e89k4QkhF4CGNoqoCA9NEGKKGADVHwVWRBUWBbZlaUoitIUdUHXrhRBQMEo1aBRkJUoWAHFAggiRSIiSE2AQMr9/pGQjSEhM2GSaffnunI555znnHPnifxycuaZ54iqYowxxv85vF2AMcYYz7BAN8aYAGGBbowxAcIC3RhjAoQFujHGBAgLdGOMCRAuBbqI9BCRbSKyQ0TG5rP9GRHZlP21XUSOer5UY4wx5yOFjUMXESewHbgGSALWA31VdUsB7f8BNFfVu8533MqVK2udOnWKUjMnTpygdOnSRdo3GFl/ucf6y33WZ+65kP7auHHjH6paJb9tIS7s3xrYoao7AUQkDugF5BvoQF9gQmEHrVOnDhs2bHDh9OdKTEykc+fORdo3GFl/ucf6y33WZ+65kP4SkT0FbXPllstFwN5cy0nZ6/I7UW2gLvCROwUaY4y5cK5coUs+6wq6T3M7sFhVM/I9kMgQYAhAdHQ0iYmJrtR4jpSUlCLvG4ysv9xj/eU+6zP3FFd/uRLoSUDNXMsxwL4C2t4O3FvQgVR1JjATIDY2Vov6J4f9eece6y/3WH+5z/rMPcXVX64E+nqgnojUBX4lK7TvyNtIRBoAFYDPPVphtr3H97Lwx4Uk7ErgSOoRKrxVgevqXscdl95BzbI1Cz+AMQEmLS2NpKQkUlNTvV0K5cqVY+vWrd4uw2+40l/h4eHExMQQGhrq8nELDXRVTReR4cBKwAnMUdXNIjIZ2KCq8dlN+wJxWgzTN65NWsu4deO4pf4tvHHtG2zfuJ36LeuzdMdS+iX0Y0qHKVwZc6WnT2uMT0tKSqJMmTLUqVMHkfzujJac5ORkypQp49Ua/Elh/aWqHDp0iKSkJOrWrevycV25QkdVE4CEPOvG51me6PJZ3bD3+F7GrRvH8w3GUf2Drzn2j75UP3yYUxUrcvsN19Opxzj+uW4cC65bYFfqJqikpqb6RJgbzxMRKlWqxMGDB93az+c/Kbrwx4X87WQrIodNQkqFU+fNhRx48QXqvLkQKRVO5LBJDDkRy5vb3vR2qcaUOAvzwFWUn63PB/pXG+NpMfNTYl5+iaoj/8WGM5G88n0azpiaVB35L2JefomWsz7jqw3xhR/MGGMCmM8H+hWfHaXCrbcS2bw5AAeST7Nj/2EWfJk1tj6yeXPK9+lD289ttgFjgsncuXPZt6+gAXcFmz59OvPnzy+GirzP5wO9wxbl9LUdcpZ7nVhMYvhoZn/wJfuPZb27f+a6K+mwxR6lZ0wwOV+gZ2Tk+1EYAIYOHcqAAQOKq6xCpaenF9uxfT7Qy5yEd058lrMsDXoQKacZo3OZEP8DAMuT11HmpAW6MSVp9+7dXHrppdxzzz20adOGfv36sXr1atq3b0+9evX46quvgKx5S+666y5atWpF8+bNeeedd3L2v/LKK2nRogUtWrTgs8+y/p2fHaPdp08fLr30Uvr160fewXOLFy9mw4YN9OvXj2bNmnHq1Cnq1KnD5MmT6dChA4sWLWLWrFm0atWKpk2bcsstt3Dy5EkAJk6cyFNPPQVA586deeCBB2jdujX169dn7dq153yfv/32Gx07dqRZs2ZcfvnlOW0++OADWrRoQdOmTenatSsAhw8fpnfv3jRp0oS2bdvy3Xff5ZxzyJAhdOvWjQEDBpCRkcGYMWNo1aoVTZo0YcaMGR75mbg0ysWbHBXKkbh+MR1rd6FZ1WZQpQG/1L6VG3a/yeKtK5nx5XE+3riU7uXLe7tUY7xm0orNbNl33KPHbFijLBNubHTeNjt27GDRokU8/fTTXHXVVSxcuJB169YRHx/P448/zvLly5kyZQpXXXUVc+bM4ejRo7Ru3Zqrr76aqlWr8uGHHxIeHs5PP/1E3759c+Z3+uabb9i8eTM1atSgffv2fPrpp3To8L+/1Pv06cOLL77IU089RWxsbM768PBw1q1bB8ChQ4cYPHgwAA8//DCzZ8/mH//4xznfQ3p6Ol999RUJCQlMmjSJ1atX/2n7woUL6d69O+PGjSMjI4OTJ09y8OBBBg8ezCeffELdunU5fPgwABMmTKB58+YsX76cjz76iAEDBrBp0yYANm7cyLp164iIiOD555+nXLlyrF+/ntOnT9O+fXu6devm1hDF/Ph8oFe4sSfjDh7knx/9k5vr3cwt9W5hV83eOFPWUy/jDV7avIJZ+9tS4cZq3i7VmKBTt25dGjduTHJyMo0aNaJr166ICI0bN2b37t0ArFq1ivj4+Jyr4tTUVH755Rdq1KjB8OHD2bRpE06nk+3bt+cct3Xr1sTExADQrFkzdu/e/adAL8htt92W8/qHH37g4Ycf5ujRo6SkpNC9e/d897n55psBaNmyZU7NubVq1Yq77rqLtLQ0evfuTbNmzUhMTKRjx445AVyxYkUA1q1bx5IlSwC46qqrOHToEMeOHQOgZ8+eREREAPDRRx+xZcsWFi9eDMCxY8f46aefgiDQ+/Xj2G23M7/rBN7O/Jb+7/fP+qRoxSiu++MP/vFNHcI++4wKyxZ7u1RjvKawK+niUqpUqZzXDocjZ9nhcOTcK1ZVlixZQoMGDf6078SJE4mOjubbb78lMzOT8PDwfI/rdDpdvu+ce0ragQMHsnz5cpo2bcrcuXMLnDvl7LkKOk/Hjh355JNPeO+99+jfvz9jxoyhfPny+Q4rzO9zlWfb5a5NVXnhhRcK/CVTVD5/Dz2sVi1q/PtJzoyZxMBPQljVbj7PxfyHVR3eZODWRnT6ZCdvNO3EZuxTasb4ou7du/PCCy/khN0333wDZF2VVq9eHYfDweuvv37eNzLzU6ZMGZKTkwvcnpycTPXq1UlLS2PBggVFrn/Pnj1UrVqVwYMHc/fdd/P111/Trl07Pv74Y3bt2gWQc8ulY8eOOedKTEykcuXKlC1b9pxjdu3alVdeeYW0tDQAtm/fzokTJ4pc41k+f4UOENWxI3XeiuPIgoXsvqMfVQ8fZnfFipTrfjW1ev7E4JDVjFxyHe/8sxOhTp//HWVMUHnkkUcYMWIETZo0QVWpU6cO7777LsOGDeOWW25h0aJFdOnSxe0HPgwcOJChQ4cSERHB55+fO4XUo48+Sps2bahdu3bObaGiSExMZNq0aYSGhhIVFcX8+fOpUqUKM2fO5OabbyYzMzPn/YCJEycyaNAgmjRpQmRkJPPmzcv3mHfeeSf79++nRYsWqCpVqlRh+fLlRaovt0KfWFRcYmNj1SMPuNi8DBYN5NG0flS+ZhR/73yx54oMEDYTnnv8pb+2bt3KZZdd5u0yAJvLxV2u9ld+P2MR2aiqsfm19//L2Ya9oX4P7g9bwuL/rmPPoQv/s8UYY/yR/we6CFz3FKEhDiY65vDwsu/zfWPCGGMCnf8HOkD5mjiueoQrZRPld67gnU3ufxzYGGP8XWAEOkCbv6E1mvNoqTd4dsWXHDlxxtsVGWNMiQqcQHc4kRufoxzJDEubz+MJ9vQUY0xwCZxAB6jeFGl3L//nXMPeb1bx2c9/eLsiY4wpMYEV6ACdx5JZvjZTS81h4tKvSU1z78MKxhj/UNTpcyFraOrZycACSeAFelhpHDf8h1q6j+uPLeSlNTu8XZExphj4S6AX53S5eQVeoANccjU0/j/uDVnB6o8/ZvvvRfuEmDGmYL42fe7GjRvp1KkTLVu2pHv37vz2228APP/88zRs2JAmTZpw++23s3v3bqZPn84zzzxDs2bNzpky9+OPP6ZZs2Y0a9aM5s2b53zCdOrUqTRu3JimTZsyduxYADZt2kTbtm1p0qQJN910E0eOHAGypuV96KGH6NSpE8899xwHDx7klltuoVWrVrRq1YovvviieH4oqlroF9AD2AbsAMYW0Ob/gC3AZmBhYcds2bKlFtWaNWsKb5R8QDOeqK1fT2ilt7y0VjMyMot8Pn/nUn+ZHP7SX1u2bPnfQsIDqnOu8+xXwgPnPf+uXbvU6XTqd999p0ePHtUWLVrooEGDNDMzU5cvX669evVSVdUHH3xQX3/9dVVVPXLkiNarV09TUlL0xIkTeurUKVVV3b59u57NhDVr1mjZsmV17969mpGRoW3bttW1a9eec/5OnTrp+vXrVVX1zJkz2q5dOz1w4ICqqsbFxemgQYNUVbV69eqampqac35V1QkTJui0adPy/b5uuOEGXbdunaqqJicna1pamiYkJGi7du30xIkTqqp66NAhVVVt3LixJiYmqqrqI488ovfdd19ObX//+99zjtm3b9+c72HPnj1av3798/btWX/6GWcDNmgBuVroXC4i4gReAq4BkoD1IhKvqltytakHPAi0V9UjIlLVo791iiKqCo7uU2j+zjDq/7qUN9fXpF+b2t6uypiA4ivT527bto0ffviBa665Bsh6YlH16tUBaNKkCf369aN379707t270O+pffv2jBw5kn79+nHzzTcTExPD6tWrGTRoEJGRkUDWdLnHjh3j6NGjdOrUCcian+XWW2/NOU7uqXxXr17Nli05kUlycnKxTJfgyuRcrYEdqroTQETigF5kXY2fNRh4SVWPAKjqAY9WWVTN7kC/fZOH97zJDe+34prLoqlaNrzw/YzxN9c+6ZXT+sr0uapKo0aN8p2k67333uOTTz4hPj6eRx99lM2bN5/3WGPHjuX6668nISGBtm3bsnr1alQ13+lyzyf3ZGOZmZl8/vnnOfOhF9fcN67cQ78I2JtrOSl7XW71gfoi8qmIfCEiPTxV4AURQW58jnBHBmMyX2PSii2F72OM8aiSmD63QYMGHDx4MCfQ09LS2Lx5M5mZmezdu5cuXbowderUnIddnG/q3Z9//pnGjRvzwAMPEBsby48//ki3bt2YM2dOzmPsDh8+TLly5ahQoULOPfjXX38952o9r27duvHiiy/mLJ99NJ2nuXKFnt+vpbyTpYQA9YDOQAywVkQuV9WjfzqQyBBgCEB0dHSBE84XJiUlxa19a9W6lWt3vcGSze/y7NuHaVbVL2YN9hh3+yvY+Ut/lStXrshTwnpCSkoKmZmZJCcnk5GRQVpaGqdOnSI5OflP20aMGMHYsWO5/PLLUVVq1arFokWLGDBgAP379ycuLo6OHTtSunRpkpOTOXnyJOnp6Tnf25kzZ0hNTT3ne73tttsYMmQIERERrF69mnnz5jF69GiOHz9Oeno6w4YNo3r16vTt25fjx4+jqgwbNgyn00mXLl0YMGAAy5YtY9q0aVxxxRU5x506dSpr167F6XTSoEEDOnToQKlSpejevTstWrQgLCyMbt26MWHCBF5++WVGjBiR80zTl19+Oac/Tpw4kVPz448/zqhRo7j88stJT0+nXbt2NGnSpNA+Tk1Nde//xYJuruv/3uxsB6zMtfwg8GCeNtOBgbmW/wu0Ot9xi/1N0dzSTmvGi230wMS/aNcpKzQlNa3I5/ZH/vImn6/wl/7K7w0zbzl+/Li3S/ArrvaXu2+KunLLZT1QT0TqikgYcDsQn6fNcqALgIhUJusWzE7Xf60Us5AwHD2fp7Ieot/J+Ty9anvh+xhjjJ8pNNBVNR0YDqwEtgJvq+pmEZksIj2zm60EDonIFmANMEZVDxVX0UVSszXS6h7uDFnF159/yHdJRwvfxxhj/IhLHyxS1QRVra+qF6vqlOx141U1Pvu1qupIVW2oqo1VNa44iy6yruOhTDWmhc1m3OJvSM/I9HZFxlwQtbn/A1ZRfraB+UnRgoSXxXHdU9RjD+0PxvHap7u9XZExRRYeHs6hQ4cs1AOQqnLo0KE/DeV0RXAN9wC47Ab00hsYuW0pN3zYjh6XV6NmxUhvV2WM22JiYkhKSuLgwYPeLoXU1FS3wyeYudJf4eHhOR+uclXwBTog100jZGciEzNf5eFllzH3rtZuf2jAGG8LDQ2lbt263i4DyJp/pXnz5t4uw28UV38F1y2Xs8rWwHH1RK6Q76n48zJWfPebtysyxpgLFpyBDhB7F3pRKyaVWsBz8Z9z7GSatysyxpgLEryB7nAiPZ+jDCe598xrPPG+PbLOGOPfgjfQAaIbIR3u42bnWn7Z+D5f7vStofPGGOOO4A50gI5jyKzwF6aWmsOEpRs4nW6PrDPG+CcL9NAIHDc+S4zu58ajb/BK4s/ersgYY4rEAh3gL52gWT+GhrzHf9d8xI4DKd6uyBhj3GaBfla3x5CI8kwJfZVxSzeRmWmfvjPG+BcL9LMiK+K49kma8BMN9r7Noo17C9/HGGN8iAV6bo1vRS++igfD3ubV99ZyMPm0tysyxhiXWaDnJoJc/x9KOZUHMmfz6IrzP3vQGGN8iQV6XhXr4ujyEFc7NnL6h3dI3OYbz7s2xpjCWKDnp+29ZEY3ZkqpeTyx7EtOnjn/E8eNMcYXWKDnxxmCo+dzVOIYf02Zy7Orf/J2RcYYUygL9IJc1BJpM5T+IavZ9OkH/PDrMW9XZIwx52WBfj5dxpFZNoYnQl9l/NKvybCx6cYYH2aBfj6lonDc8B8uJokr9i9g3me7vV2RMcYUyAK9MPW7ow17c1/ochavWsOvR095uyJjjMmXS4EuIj1EZJuI7BCRsflsHygiB0VkU/bXPZ4v1Xvk2n/jDItgosxi/LLv7aG8xhifVGigi4gTeAm4FmgI9BWRhvk0fUtVm2V/verhOr2rTDUc3SbTWrZQccci3v9hv7crMsaYc7hyhd4a2KGqO1X1DBAH9CresnxQizvRmm0ZH7aQ5975jGOn7JF1xhjfIoXdPhCRPkAPVb0ne7k/0EZVh+dqMxB4AjgIbAf+parnzG4lIkOAIQDR0dEt4+LiilR0SkoKUVFRRdr3QkSe2EvLDSNYkd6ad6qN4M5GpUq8hqLwVn/5K+sv91mfuedC+qtLly4bVTU2v20hLuwv+azL+1tgBfCmqp4WkaHAPOCqc3ZSnQnMBIiNjdXOnTu7cPpzJSYmUtR9L1hkEr0/fpJlv15J1PVDia1T0Tt1uMGr/eWHrL/cZ33mnuLqL1duuSQBNXMtxwD7cjdQ1UOqenZqwllAS8+U54OuHElmxUt4otRrTFqynjPpmd6uyBhjANcCfT1QT0TqikgYcDsQn7uBiFTPtdgT2Oq5En1MSCkcPZ+nhh7ghiPzmPmJPbLOGOMbCg10VU0HhgMryQrqt1V1s4hMFpGe2c3+KSKbReRb4J/AwOIq2CfUaQ8t7mRwyPus/uhDdh60R9YZY7zPpXHoqpqgqvVV9WJVnZK9bryqxme/flBVG6lqU1Xtoqo/FmfRPuGaSWhkJaaEzOKRpd/a2HRjjNfZJ0WLKqICzuum0oidXPrLQhZvTPJ2RcaYIGeBfiEa3YTW686Y0EW89t7HHEqxR9YZY7zHAv1CiCDXP0VYiJP7M2bx2LtbvF2RMSaIWaBfqPK1cHR9hM6OTaR9t4S1Px30dkXGmCBlge4Jbf5GZvXmTC41nyeWfsGpMxnersgYE4Qs0D3B4cTR8zkqkEL/5Nk8/5E9ss4YU/Is0D2lelOk3b30DVnDprXvsvW3496uyBgTZCzQPanzWDLK1ebx0NmMX7LRHllnjClRFuieFFYa543/oS776LB/Pm98scfbFRljgogFuqddcjXa+FbuDYlnycr/sv9YqrcrMsYECQv0YiDdn0BKRTGeGUx85ztvl2OMCRIW6MUhqgrOHlOIlW1U2BbHys32yDpjTPGzQC8uzfqRWbsD40LjeH75WpJT7ZF1xpjiZYFeXERw3Pgckc50hqXO4qmV27xdkTEmwFmgF6fKl+DoNIbrnV/y61dL+eaXI96uyBgTwCzQi9sV95FR+VIeC53H5CVfkpZhj6wzxhQPC/TiFhKGs9cLRHOIGw+9xqtrd3m7ImNMgLJALwk1WyOt7mZgyEr+uzqBPYdOeLsiY0wAskAvKV3Ho6Wjecw5iwnLNtkj64wxHmeBXlLCy+G84SkulT002PU6yzf96u2KjDEBxqVAF5EeIrJNRHaIyNjztOsjIioisZ4rMYBcdiPa4HpGhi7ltRVrOHLijLcrMsYEkEIDXUScwEvAtUBDoK+INMynXRngn8CXni4ykMh10wgJDeX+9BlMec8eWWeM8RxXrtBbAztUdaeqngHigF75tHsUmArYbFTnU+4inNdMpIPje9I3vcVnO/7wdkXGmAAR4kKbi4C9uZaTgDa5G4hIc6Cmqr4rIqMLOpCIDAGGAERHR5OYmOh2wQApKSlF3tcn6F9oVqYBE5Jf57YFTRndIZowpxTb6fy+v0qY9Zf7rM/cU1z95Uqg55c0OUM0RMQBPAMMLOxAqjoTmAkQGxurnTt3dqnIvBITEynqvj6j4WtkTu/IkPQFfJ/xFKO6Nii2UwVEf5Ug6y/3WZ+5p7j6y5VbLklAzVzLMcC+XMtlgMuBRBHZDbQF4u2N0UJEN8LR4T76OD9h08fvsP33ZG9XZIzxc64E+nqgnojUFZEw4HYg/uxGVT2mqpVVtY6q1gG+AHqq6oZiqTiQdBxDRvm6TAmdzYQlG8i0R9YZYy5AoYGuqunAcGAlsBV4W1U3i8hkEelZ3AUGtNAInD2fpRb7ab/vNRZ+9Yu3KzLG+DFX7qGjqglAQp514wto2/nCywoif+mMNu3L0G/f5v/ev5JrGvYnumy4t6syxvgh+6SoD5BuU5DwcoxnOpPj7ZF1xpiisUD3BaUr4bz2SZrJDipuXcDqLb97uyJjjB+yQPcVTf6PzLpdGBv6Fi8sT+TE6XRvV2SM8TMW6L5CBMeNzxDhVIadmsnTq7Z7uyJjjJ+xQPclFevi6PIg3Z0b2PfF23yXdNTbFRlj/IgFuq9pdy8ZVS9ncug8Ji/+gnR7ZJ0xxkUW6L7GGYqz1/NU4Qg9/3iVOZ/aI+uMMa6xQPdFF7WENn/jryGrWfPhu+w9fNLbFRlj/IAFuo+Sqx4ms0wNJjtmMmHZN/bIOmNMoSzQfVWpMoTc8DT1JInLds5lxXe/ebsiY4yPs0D3ZQ2uJbNhb+4LXcbc+A85djLN2xUZY3yYBbqPc1z7b5xhEdyfNp0nEuyRdcaYglmg+7oy1XB2m0xbxxYyvnmDL3ce8nZFxhgfZYHuD1rcSUZMWx4OXci/l6zldHqGtysyxvggC3R/4HDg7PU8ZRyn6X98Jq8k/uztiowxPsgC3V9UaYDjypHc5PyU7xKXsuNAircrMsb4GAt0f9JhJOkVLuHRkFeZtHi9PbLOGPMnFuj+JDSckF7PcREHab/vVd7esNfbFRljfIgFur+p0wFtPoDBIQksTUjgYPJpb1dkjPERFuh+SLpNRiMq8UjmDB5d8b23yzHG+AiXAl1EeojINhHZISJj89k+VES+F5FNIrJORBp6vlSTI6ICIdf/m8aOnVTePJc12w54uyJjjA8oNNBFxAm8BFwLNAT65hPYC1W1sao2A6YC//F4pebPGt1MxiXXMCZ0ES8s/YiTZ+yRdcYEO1eu0FsDO1R1p6qeAeKAXrkbqOrxXIulARt+UdxEcN7wH8JChHtPTufZD+2RdcYEO1cC/SIg93CKpOx1fyIi94rIz2Rdof/TM+WZ8ypfC2fXR+jq/IbfPn+TH3495u2KjDFeJIXNsy0itwLdVfWe7OX+QGtV/UcB7e/Ibn9nPtuGAEMAoqOjW8bFxRWp6JSUFKKiooq0b6CRzAyabhxDesofDAx7mpFXVMYh8qc21l/usf5yn/WZey6kv7p06bJRVWPz2xbiwv5JQM1cyzHAvvO0jwNeyW+Dqs4EZgLExsZq586dXTj9uRITEynqvgHpstfInNmFO04tYFfoM9zdoe6fNlt/ucf6y33WZ+4prv5y5ZbLeqCeiNQVkTDgdiA+dwMRqZdr8XrgJ8+VaApVvSnSdhh3hKwhcdUyfj16ytsVGWO8oNBAV9V0YDiwEtgKvK2qm0Vksoj0zG42XEQ2i8gmYCRwzu0WU7yky4Okl63JJJnF5GVf2yPrjAlCrtxyQVUTgIQ868bnen2fh+sy7gorTciNz/KXBbdw2c+v8v4Pf+G6xtW9XZUxpgTZJ0UDSb2ryby8D/eGxPPaOys5dsoeWWdMMLFADzCOHk8ipUoz5swrTHvfHllnTDCxQA80UVUI6fE4rR0/kr5xPht2H/Z2RcaYEmKBHoia9SOjVgfGhS5k2uKPSbd5040JChbogUgEZ8/niHSk0//YdBJ22b10Y4KBBXqgqnwJzk73c4PzC5J3fsmXOw95uyJjTDGzQA9k7e8jvVIDHg19jZFz/8t6u59uTECzQA9kIWGE3PQKlR3JvB7yGCPnfGhvkhoTwCzQA11MS35o/Ah1HQeYH/IYI19bzcY9R7xdlTGmGFigB4GjFZogd7xFHcdB5jke5V9zPuTrXyzUjQk0FujB4i+dkH5vU8d5kHmOyYycvYpNe496uypjjAdZoAeTuh2Rfouo7fyDuY7JjJi9ku+SLNSNCRQW6MGm7pU4/rqYWs5DzJVJ3PfqSr5PsicdGRMILNCDUZ0OOP66hFohR3hNJjHi1Q/s8XXGBAAL9GBVp31OqM/JDvXN+yzUjfFnFujBrPYVOP66hJohR5jNJO6b9QFb9h33dlXGmCKyQA92ta/A8del1Aw5ymydyIhZCfy430LdGH9kgW6gdjsc/ZdSM/QYr+pE7puZwLb9yd6uyhjjJgt0k6VWWxz9lxETmsyszIncN/M9tv9uoW6MP7FAN/9Tqw2OAVmhPjNzAiNmvseOAxbqxvgLC3TzZzVbZ4d6CjMyJvDPGQnsOJDi7aqMMS5wKdBFpIeIbBORHSIyNp/tI0Vki4h8JyL/FZHani/VlJiarXEMWE6NsBPMyBjPiJnv8vNBC3VjfF2hgS4iTuAl4FqgIdBXRBrmafYNEKuqTYDFwFRPF2pKWM1WOLNDfXr6eO6b8S67/jjh7aqMMefhyhV6a2CHqu5U1TNAHNArdwNVXaOqJ8Y1sisAAA+SSURBVLMXvwBiPFum8YqYWJwDllM97CSvpI9nxIwV7LZQN8Znier5HyAsIn2AHqp6T/Zyf6CNqg4voP2LwH5VfSyfbUOAIQDR0dEt4+LiilR0SkoKUVFRRdo3GF1of5U5vp3G307g9/TSDJVHuLN1TapGBu7bL/b/l/usz9xzIf3VpUuXjaoam+9GVT3vF3Ar8Gqu5f7ACwW0/StZV+ilCjtuy5YttajWrFlT5H2DkUf6K2mDpk+J0aQJF+tNUxbqnj9OXPgxfZT9/+U+6zP3XEh/ARu0gFx15TIrCaiZazkG2Je3kYhcDYwDeqrqaVd/2xg/cVFLnHe+Q7Ww07xw5hH+NSOevYdPFr6fMabEuBLo64F6IlJXRMKA24H43A1EpDkwg6wwP+D5Mo1PuKgFzoHxVAs7zfNnHmbE9HiSjlioG+MrCg10VU0HhgMrga3A26q6WUQmi0jP7GbTgChgkYhsEpH4Ag5n/F2N5jgHxhNd6kxOqP969JS3qzLGACGuNFLVBCAhz7rxuV5f7eG6jC+r0ZyQO+OJntuT50+P41/T4ZmhvahRPsLblRkT1AJ3qIIpXjWaETIwnqphaTx76iFGzljOb8fsSt0Yb7JAN0VXoxkhg1ZQJTyDZ06OY9T0Zew/lurtqowJWhbo5sJUb0rIwKxQf/rkw4yesYzfj1uoG+MNFujmwlVvQsigd6kcnsm0E+MYNWMZByzUjSlxFujGM6o1JnTQCiqHZ/JUykNZoZ5soW5MSbJAN55TrTGhg96lUjhMS3mI+6cv42CyfcbMmJJigW48q9rlhN6VFer/TnmQMTOW8keKhboxJcEC3XhedCNC73qXiuHC1OQHuX/6Ug5ZqBtT7CzQTfGIbkToXe9RPlx4MvlBHpixhMMnzni7KmMCmgW6KT7RDQm7O4HyEQ6mHH+I+2cs4YiFujHFxgLdFK+qlxF2VwIVIhw8fmwsD8xYzNGTFurGFAcLdFP8ql5K2F0JlI8I4bFjDzJ25mKOnUzzdlXGBBwLdFMyql5K2N0JlIsI4dEjYxk7YxHHTlmoG+NJFuim5FRpQKm7EygbEcrko2MZZ6FujEdZoJuSVaUBpe5+n7IRYUw88gAPz1zE8VQLdWM8wQLdlLwq9Sl1z/tERZRi4uGsUE+2UDfmglmgG++oXI/we96ndEQpJhx6gEdmLSLldLq3qzLGr1mgG++pXI/wez6gdEQ4j/zxAI/MfNtC3ZgLYIFuvKvyJYQPzgr1h/+4nwkz3+aEhboxRWKBbryv0sWED/6AyIhIHvrjfibMeouTZyzUjXGXS4EuIj1EZJuI7BCRsfls7ygiX4tIuoj08XyZJuBVupiIwe9nhfrB+5k46y1OncnwdlXG+JVCA11EnMBLwLVAQ6CviDTM0+wXYCCw0NMFmiCSHeoRkVGMPXA/k16Ns1A3xg2uXKG3Bnao6k5VPQPEAb1yN1DV3ar6HZBZDDWaYJId6uGRUTzw+/08+upbpKZZqBvjClHV8zfIuoXSQ1XvyV7uD7RR1eH5tJ0LvKuqiws41hBgCEB0dHTLuLi4IhWdkpJCVFRUkfYNRv7YX+Gn9nPZxnFkpqUyPmIcN7a6jDCnlMi5/bG/vM36zD0X0l9dunTZqKqx+W0LcWH//P4Vnf+3QAFUdSYwEyA2NlY7d+5clMOQmJhIUfcNRn7bX23acGLWtTx68jGe/ukpxt19G+GhzmI/rd/2lxdZn7mnuPrLlVsuSUDNXMsxwD6PV2JMXhXrUnrIB4RGlmXUb6N5YnYcp9Pt9osxBXEl0NcD9USkroiEAbcD8cVbljHZKtSh9JAPCIksx79+G8OTFurGFKjQQFfVdGA4sBLYCrytqptFZLKI9AQQkVYikgTcCswQkc3FWbQJMhXqEJUd6iP2jebfs9+0UDcmHy6NQ1fVBFWtr6oXq+qU7HXjVTU++/V6VY1R1dKqWklVGxVn0SYIVahN1JAPcEaW5759Y5g6J44z6Taoypjc7JOixn9UqE3U31biiKzAfb+OZtqchaRlWKgbc5YFuvEv5WtR5m8rkcgK/OPXMTxtoW5MDgt043/K16TM31ZCZEWGJY3m6dcs1I0BC3Tjr8rXpOzQlRBZiWF7R/Ps3IWkW6ibIGeBbvxXuRjKDl2JRlZm6C+jeW6ehboJbhboxr+Vi6Hc0JVkRlZiyJ7RPG+hboKYBbrxf+UuotzQVWREVmbwntG8OG8BGZlFmp3CGL9mgW4CQ7mLKP/3VWREVuGePaN5yULdBCELdBM4ytag/N9XkhZZlbt2j+Ll+RbqJrhYoJvAUrYGFf6+ijORVRm0axTT579BpoW6CRIW6CbwlK1Oxb+v4kxEVQbuGsXMNyzUTXCwQDeBqWx1KgxbRWpENfr/PIpZb7xuoW4CngW6CVhStjoVh60kNaI6f/15NLMXvEFhT+gyxp9ZoJuAJmWrU/HelZyKqE6/HaOYY6FuApgFugl4UqYale5dxcmI6vT9aRRzF7xuoW4CkgW6CQpSJppK967iREQNbvtpNPMW2pW6CTwW6CZoSJloKt+7kpSIGty2fSSvL7QrdRNYLNBNUJEy0VQZvorkiIu4dfsoFrw530LdBAwLdBN0JKoqVYav4nhEDH22jeLNOLtSN4HBAt0EJYmqStXhqzgaUYubfxxJ3FsW6sb/uRToItJDRLaJyA4RGZvP9lIi8lb29i9FpI6nCzXG0ySqClXvXcnRiFrctHUkb79lt1+Mfys00EXECbwEXAs0BPqKSMM8ze4GjqjqJcAzwL89XagxxcFRpgpVh6/iSEQtem0dxZJFFurGf4W40KY1sENVdwKISBzQC9iSq00vYGL268XAiyIiav8yjB9wRFUmevgq9r/YnRs3j2JmpQeocElzb5flV3YezaD83qPeLsNvHD9dPNHoSqBfBOzNtZwEtCmojaqmi8gxoBLwhyeKNKa4OaIqU234Kva/2I17D00h9dVp3i7Jr9QH+MbbVfiP3VUGQfcuHj+uK4Eu+azL++vFlTaIyBBgCEB0dDSJiYkunP5cKSkpRd43GFl/uc7RYjx7flxOmKR7uxS/kp6eQUiI09tl+I2wstWK5d+kK4GeBNTMtRwD7CugTZKIhADlgMN5D6SqM4GZALGxsdq5c+cilAyJiYkUdd9gZP3lnsSwcrSz/nKL/T/mnuLqL1dGuawH6olIXREJA24H4vO0iQfuzH7dB/jI7p8bY0zJKvQKPfue+HBgJeAE5qjqZhGZDGxQ1XhgNvC6iOwg68r89uIs2hhjzLlcueWCqiYACXnWjc/1OhW41bOlGWOMcYd9UtQYYwKEBboxxgQIC3RjjAkQFujGGBMgLNCNMSZAiLeGi4vIQWBPEXevjE0r4A7rL/dYf7nP+sw9F9JftVW1Sn4bvBboF0JENqhqrLfr8BfWX+6x/nKf9Zl7iqu/7JaLMcYECAt0Y4wJEP4a6DO9XYCfsf5yj/WX+6zP3FMs/eWX99CNMcacy1+v0I0xxuRhgW6MMQHCAt0YYwKEXwe6iFzq7RqMMcZX+HWgA6u8XYA/EZHvvV2DvxGRQd6uwQQGEYkWkRYi0lxEoovjHC494MKbROT5gjYB5UuyFn8gIjcXtAmoVpK1BIhJwGveLsKXiEg54EGgN3D2I+gHgHeAJ1X1qLdq80Ui0gyYTtazln/NXh0jIkeBYar6tcfO5evDFkUkGRgFnM5n89OqWrmES/JpIpIGLADy+8H2UdUyJVySzxOR7wraBNRX1VIlWY+vE5GVwEfAPFXdn72uGlnPFb5aVa/xZn2+RkQ2AX9T1S/zrG8LzFDVph47lx8E+kfAw6r6WT7bdqlqXS+U5bNEZCNwp6r+kM+2vapa0wtl+TQR+R3oDhzJuwn4TFVrlHxVvktEtqlqA3e3BSsR+UlV6xWwbYeqXuKpc/n8LRegD5Ca3wYL83yNAI4XsO2mkizEj7wLRKnqprwbRCSx5MvxeXtE5H6yrtB/h6z7w8BAYK83C/NR74vIe8B8/tc/NYEBwAeePJHPX6HnJiIVAVXVvFdSxpgSIiIVgLFAL6Bq9urfgXiy7qHbv888RORasvrrIrL+8ksC4lU1waPn8fVAF5FawFSgK3CUrM4oS9Y9vLGqutt71fkXEblBVd/1dh0mcInIIFW1N5G9xB+GLb4FLAOqqWq97PtN1YHlQJxXK/M/rbxdgAl4k7xdgK8RkXIi8qSIbBWRQ9lfW7PXeXSknj9coZ/vDYUCtwWz7A9cnf3zToF9ZP15t9WrhZmAYKOC3HOeUUEDga6eHBXkD4EeBxwG5vHnNxTuBCqr6v95qzZfJCIPAH3J+uslKXt1DHA7EKeqT3qrNhMYbFSQe0pyVJA/BHoYcDd/fkNhL7ACmK2q+Y1PD1oish1opKppedaHAZvtLxpzoURkNvCaqq7LZ9tCVb3DC2X5LBFZBawm/1FB16jq1R47l68HunGPiPwIdFfVPXnW1wZW2RhhY0pWSY4K8utAt1Eb5xKRHsCLwE/87xZVLeASYLiqenTcqzGm6Dw9KsjfA32Sqk7wdh2+RkQcQGv+POZ1vapmeLUwY8yfiMgvqlrLY8fzh0C3URvGGH9VkqOCfP6j/3lGbXyVvToGeFNEbNSGMcbXRXOeUUGePJHPX6HbqA1jjD8ryVFBPn+FDmQCNYA9edZXz95mjDE+S1XvPs82jw7x9IdAHwH8V0TyHbXhtaqMMcbH+PwtF7BRG8YY4wq/CHRjjDGF84fZFo0xxrjAAt0YYwKEBboJeCJyk4ho9gfUEJE6InLOM1fz7FNoG2N8jQW6CQZ9gXVkTSFsTMCyQDcBTUSigPZkTcF8TqCLyEAReUdEPhCRbSKSe24gp4jMEpHNIrJKRCKy9xksIutF5FsRWSIikSXz3RhzfhboJtD1Bj5Q1e3AYRFpkU+b1kA/oBlwq4jEZq+vB7ykqo3Iep7tLdnrl6pqK1VtCmwl65eFMV5ngW4C3dl5gMj+b9982nyoqodU9RSwFOiQvX6Xqm7Kfr0RqJP9+nIRWSsi35P1i6BRsVRujJv84ZOixhSJiFQCriIrgBVwkjVb58t5mub9MMbZ5dxPw8oAIrJfzwV6q+q3IjIQ6Oy5qo0pOrtCN4GsDzBfVWurah1VrQnsImu2ztyuEZGK2ffIewOfFnLcMsBvIhJK1hW6MT7BAt0Esr7AsjzrlgAP5Vm3Dngd2AQsUdUNhRz3EeBL4EPgRw/UaYxH2Ef/TVDLvmUSq6o20Zvxe3aFbowxAcKu0I0xJkDYFboxxgQIC3RjjAkQFujGGBMgLNCNMSZAWKAbY0yAsEA3xpgA8f/+feCiFMVh2AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(result_lasso.shape[0]), result_lasso['mean_train_score'], label = 'mean train score')\n",
    "plt.plot(range(result_lasso.shape[0]), result_lasso['mean_test_score'], label = 'mean test score')\n",
    "plt.xticks(range(result_lasso.shape[0]), result_lasso['param_alpha'], rotation = 90)\n",
    "plt.plot([grid_search_lasso.best_index_], result_lasso['mean_train_score'][grid_search_lasso.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.plot([grid_search_lasso.best_index_], result_lasso['mean_test_score'][grid_search_lasso.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('Alpha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression Summary:\n",
    "\n",
    "#### Train Score: 0.0\n",
    "\n",
    "#### Test Score: -2.8006\n",
    "\n",
    "#### Best Parameters: {'alpha' : 0.01}\n",
    "\n",
    "#### Best Cross - Validation Score: 0.6686"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree),\n",
    "                         LinearRegression(**kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_poly = {'polynomialfeatures__degree': np.arange(3)}\n",
    "\n",
    "grid_poly = GridSearchCV(PolynomialRegression(), param_grid_poly,return_train_score=True,n_jobs=-1,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('polynomialfeatures',\n",
       "                                        PolynomialFeatures(degree=2,\n",
       "                                                           include_bias=True,\n",
       "                                                           interaction_only=False,\n",
       "                                                           order='C')),\n",
       "                                       ('linearregression',\n",
       "                                        LinearRegression(copy_X=True,\n",
       "                                                         fit_intercept=True,\n",
       "                                                         n_jobs=None,\n",
       "                                                         normalize=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'polynomialfeatures__degree': array([0, 1, 2])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_poly.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'polynomialfeatures__degree': 2}\n",
      "Best cross-validation score: 0.7070\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_poly.best_params_))\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid_poly.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7521345246769945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7053224874928257"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol = PolynomialFeatures(degree = 2)\n",
    "X_pol = pol.fit_transform(X_train_pca)\n",
    "Xt_pol = pol.fit_transform(X_test_pca)\n",
    "pol_reg = LinearRegression()\n",
    "pol_reg.fit(X_pol,y_train)\n",
    "print(pol_reg.score(X_pol, y_train))\n",
    "pol_reg_test_score = pol_reg.score(Xt_pol, y_test)\n",
    "pol_reg_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[0.68262275 0.75739177 0.72060185 0.69318027 0.69318301 0.68962393]\n",
      "0.7061005984499915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "  \n",
    "kfold = KFold(n_splits=6)\n",
    "print(\"Cross-validation scores:\\n{}\".format(cross_val_score(pol_reg , X_pol, y_train, cv=kfold)))\n",
    "scores = cross_val_score(pol_reg , X_pol, y_train, cv=kfold)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_polynomialfeatures__degree</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002567</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0</td>\n",
       "      <td>{'polynomialfeatures__degree': 0}</td>\n",
       "      <td>-0.002549</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>-0.000992</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000864</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004365</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.001870</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>1</td>\n",
       "      <td>{'polynomialfeatures__degree': 1}</td>\n",
       "      <td>0.647628</td>\n",
       "      <td>0.717941</td>\n",
       "      <td>0.682920</td>\n",
       "      <td>0.699653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688448</td>\n",
       "      <td>0.023364</td>\n",
       "      <td>2</td>\n",
       "      <td>0.705899</td>\n",
       "      <td>0.688213</td>\n",
       "      <td>0.697795</td>\n",
       "      <td>0.693616</td>\n",
       "      <td>0.695159</td>\n",
       "      <td>0.696137</td>\n",
       "      <td>0.005799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016755</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>2</td>\n",
       "      <td>{'polynomialfeatures__degree': 2}</td>\n",
       "      <td>0.672797</td>\n",
       "      <td>0.764937</td>\n",
       "      <td>0.688215</td>\n",
       "      <td>0.689420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707032</td>\n",
       "      <td>0.032735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.764474</td>\n",
       "      <td>0.744550</td>\n",
       "      <td>0.759428</td>\n",
       "      <td>0.754729</td>\n",
       "      <td>0.756421</td>\n",
       "      <td>0.755920</td>\n",
       "      <td>0.006579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.002567      0.000376         0.001874        0.000222   \n",
       "1       0.004365      0.000564         0.001870        0.000447   \n",
       "2       0.016755      0.001716         0.004986        0.000889   \n",
       "\n",
       "  param_polynomialfeatures__degree                             params  \\\n",
       "0                                0  {'polynomialfeatures__degree': 0}   \n",
       "1                                1  {'polynomialfeatures__degree': 1}   \n",
       "2                                2  {'polynomialfeatures__degree': 2}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0          -0.002549          -0.000035          -0.000146          -0.000992   \n",
       "1           0.647628           0.717941           0.682920           0.699653   \n",
       "2           0.672797           0.764937           0.688215           0.689420   \n",
       "\n",
       "   ...  mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0  ...        -0.000864        0.000910                3            0.000000   \n",
       "1  ...         0.688448        0.023364                2            0.705899   \n",
       "2  ...         0.707032        0.032735                1            0.764474   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.000000            0.000000            0.000000   \n",
       "1            0.688213            0.697795            0.693616   \n",
       "2            0.744550            0.759428            0.754729   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.000000          0.000000         0.000000  \n",
       "1            0.695159          0.696137         0.005799  \n",
       "2            0.756421          0.755920         0.006579  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_poly = pd.DataFrame(grid_poly.cv_results_)\n",
    "result_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee50c01a90>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee50c01eb8>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x1ee50ac7160>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50ac4a90>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50ac4518>],\n",
       " <a list of 3 Text xticklabel objects>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee50a99cf8>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee50c0e860>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Degree')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ee50c0ef28>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(result_poly.shape[0]), result_poly['mean_train_score'], label = 'mean train score')\n",
    "plt.plot(range(result_poly.shape[0]), result_poly['mean_test_score'], label = 'mean test score')\n",
    "plt.xticks(range(result_poly.shape[0]), result_poly['param_polynomialfeatures__degree'], rotation = 90)\n",
    "plt.plot([grid_poly.best_index_], result_poly['mean_train_score'][grid_poly.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.plot([grid_poly.best_index_], result_poly['mean_test_score'][grid_poly.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.grid()\n",
    "plt.xlabel('Degree')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression Summary:\n",
    "\n",
    "#### Train Score: 0.7521\n",
    "\n",
    "#### Test Score: 0.7053\n",
    "\n",
    "#### Best Parameters: {'polynomialfeatures_degree' : 2}\n",
    "\n",
    "#### Best Cross -  Validation Score: 0.7070"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parms_svrl = {'C': [0.01, 0.1, 1, 10, 100], 'epsilon' : [0.01, 0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearsvr = LinearSVR()\n",
    "grid_svrl = GridSearchCV(estimator = linearsvr,param_grid = grid_parms_svrl,return_train_score=True,n_jobs= -1,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=LinearSVR(C=1.0, dual=True, epsilon=0.0,\n",
       "                                 fit_intercept=True, intercept_scaling=1.0,\n",
       "                                 loss='epsilon_insensitive', max_iter=1000,\n",
       "                                 random_state=None, tol=0.0001, verbose=0),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
       "                         'epsilon': [0.01, 0.1, 1, 10, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svrl.fit(X_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.1, 'epsilon': 0.1}\n",
      "Best cross-validation score: 0.6867\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_svrl.best_params_))\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid_svrl.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVR(C=0.1, dual=True, epsilon=0.1, fit_intercept=True,\n",
       "          intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "          random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6948118676692552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6802542121945057"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvr = LinearSVR(C = 0.1, epsilon = 0.1)\n",
    "        \n",
    "lsvr.fit(X_train_pca, y_train)\n",
    "\n",
    "print(lsvr.score(X_train_pca, y_train))\n",
    "lsvr_test_score = lsvr.score(X_test_pca, y_test)\n",
    "lsvr_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[0.6784012  0.61142764 0.75746969 0.66609235 0.72486611 0.64435077\n",
      " 0.67436107 0.72612311 0.73858256 0.64564558]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6867527834969056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "  \n",
    "kfold = KFold(n_splits=10)\n",
    "print(\"Cross-validation scores:\\n{}\".format(cross_val_score(lsvr , X_train_pca, y_train, cv=kfold)))\n",
    "scores = cross_val_score(lsvr, X_train_pca, y_train, cv=kfold)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_epsilon</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004972</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.01, 'epsilon': 0.01}</td>\n",
       "      <td>0.684228</td>\n",
       "      <td>0.609148</td>\n",
       "      <td>0.751710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683043</td>\n",
       "      <td>0.695891</td>\n",
       "      <td>0.689057</td>\n",
       "      <td>0.698055</td>\n",
       "      <td>0.694044</td>\n",
       "      <td>0.688142</td>\n",
       "      <td>0.687181</td>\n",
       "      <td>0.697096</td>\n",
       "      <td>0.692741</td>\n",
       "      <td>0.005382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006087</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.01, 'epsilon': 0.1}</td>\n",
       "      <td>0.677519</td>\n",
       "      <td>0.605177</td>\n",
       "      <td>0.748425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682220</td>\n",
       "      <td>0.695473</td>\n",
       "      <td>0.688364</td>\n",
       "      <td>0.696216</td>\n",
       "      <td>0.693590</td>\n",
       "      <td>0.687927</td>\n",
       "      <td>0.686750</td>\n",
       "      <td>0.696642</td>\n",
       "      <td>0.692001</td>\n",
       "      <td>0.005240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.01, 'epsilon': 1}</td>\n",
       "      <td>-10.562007</td>\n",
       "      <td>-11.829240</td>\n",
       "      <td>-8.465385</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.821266</td>\n",
       "      <td>-10.558814</td>\n",
       "      <td>-10.513738</td>\n",
       "      <td>-10.399740</td>\n",
       "      <td>-10.355896</td>\n",
       "      <td>-10.657840</td>\n",
       "      <td>-10.642934</td>\n",
       "      <td>-10.432109</td>\n",
       "      <td>-10.531052</td>\n",
       "      <td>0.137191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 0.01, 'epsilon': 10}</td>\n",
       "      <td>-10.562007</td>\n",
       "      <td>-11.829240</td>\n",
       "      <td>-8.465385</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.821266</td>\n",
       "      <td>-10.558814</td>\n",
       "      <td>-10.513738</td>\n",
       "      <td>-10.399740</td>\n",
       "      <td>-10.355896</td>\n",
       "      <td>-10.657840</td>\n",
       "      <td>-10.642934</td>\n",
       "      <td>-10.432109</td>\n",
       "      <td>-10.531052</td>\n",
       "      <td>0.137191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 0.01, 'epsilon': 100}</td>\n",
       "      <td>-10.562007</td>\n",
       "      <td>-11.829240</td>\n",
       "      <td>-8.465385</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.821266</td>\n",
       "      <td>-10.558814</td>\n",
       "      <td>-10.513738</td>\n",
       "      <td>-10.399740</td>\n",
       "      <td>-10.355896</td>\n",
       "      <td>-10.657840</td>\n",
       "      <td>-10.642934</td>\n",
       "      <td>-10.432109</td>\n",
       "      <td>-10.531052</td>\n",
       "      <td>0.137191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.044006</td>\n",
       "      <td>0.008296</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 0.01}</td>\n",
       "      <td>0.682835</td>\n",
       "      <td>0.609998</td>\n",
       "      <td>0.757065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682932</td>\n",
       "      <td>0.695794</td>\n",
       "      <td>0.689074</td>\n",
       "      <td>0.697641</td>\n",
       "      <td>0.694499</td>\n",
       "      <td>0.687884</td>\n",
       "      <td>0.687125</td>\n",
       "      <td>0.697161</td>\n",
       "      <td>0.692699</td>\n",
       "      <td>0.005437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.046222</td>\n",
       "      <td>0.018398</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 0.1}</td>\n",
       "      <td>0.678101</td>\n",
       "      <td>0.611903</td>\n",
       "      <td>0.757334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685222</td>\n",
       "      <td>0.697605</td>\n",
       "      <td>0.691330</td>\n",
       "      <td>0.699895</td>\n",
       "      <td>0.696579</td>\n",
       "      <td>0.690786</td>\n",
       "      <td>0.689518</td>\n",
       "      <td>0.699497</td>\n",
       "      <td>0.694924</td>\n",
       "      <td>0.005248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 1}</td>\n",
       "      <td>-10.562007</td>\n",
       "      <td>-11.829240</td>\n",
       "      <td>-8.465385</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.821266</td>\n",
       "      <td>-10.558814</td>\n",
       "      <td>-10.513738</td>\n",
       "      <td>-10.399740</td>\n",
       "      <td>-10.355896</td>\n",
       "      <td>-10.657840</td>\n",
       "      <td>-10.642934</td>\n",
       "      <td>-10.432109</td>\n",
       "      <td>-10.531052</td>\n",
       "      <td>0.137191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 10}</td>\n",
       "      <td>-10.562007</td>\n",
       "      <td>-11.829240</td>\n",
       "      <td>-8.465385</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.821266</td>\n",
       "      <td>-10.558814</td>\n",
       "      <td>-10.513738</td>\n",
       "      <td>-10.399740</td>\n",
       "      <td>-10.355896</td>\n",
       "      <td>-10.657840</td>\n",
       "      <td>-10.642934</td>\n",
       "      <td>-10.432109</td>\n",
       "      <td>-10.531052</td>\n",
       "      <td>0.137191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 100}</td>\n",
       "      <td>-10.562007</td>\n",
       "      <td>-11.829240</td>\n",
       "      <td>-8.465385</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.821266</td>\n",
       "      <td>-10.558814</td>\n",
       "      <td>-10.513738</td>\n",
       "      <td>-10.399740</td>\n",
       "      <td>-10.355896</td>\n",
       "      <td>-10.657840</td>\n",
       "      <td>-10.642934</td>\n",
       "      <td>-10.432109</td>\n",
       "      <td>-10.531052</td>\n",
       "      <td>0.137191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.160484</td>\n",
       "      <td>0.017751</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'epsilon': 0.01}</td>\n",
       "      <td>0.685693</td>\n",
       "      <td>0.608131</td>\n",
       "      <td>0.759070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680484</td>\n",
       "      <td>0.692493</td>\n",
       "      <td>0.688583</td>\n",
       "      <td>0.694825</td>\n",
       "      <td>0.692675</td>\n",
       "      <td>0.687827</td>\n",
       "      <td>0.683331</td>\n",
       "      <td>0.696750</td>\n",
       "      <td>0.691214</td>\n",
       "      <td>0.005882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.175263</td>\n",
       "      <td>0.015393</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1, 'epsilon': 0.1}</td>\n",
       "      <td>0.676927</td>\n",
       "      <td>0.607622</td>\n",
       "      <td>0.757675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683756</td>\n",
       "      <td>0.696778</td>\n",
       "      <td>0.691061</td>\n",
       "      <td>0.698690</td>\n",
       "      <td>0.695592</td>\n",
       "      <td>0.690382</td>\n",
       "      <td>0.688441</td>\n",
       "      <td>0.696006</td>\n",
       "      <td>0.693768</td>\n",
       "      <td>0.005073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1, 'epsilon': 1}</td>\n",
       "      <td>-10.562007</td>\n",
       "      <td>-11.829240</td>\n",
       "      <td>-8.465385</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.821266</td>\n",
       "      <td>-10.558814</td>\n",
       "      <td>-10.513738</td>\n",
       "      <td>-10.399740</td>\n",
       "      <td>-10.355896</td>\n",
       "      <td>-10.657840</td>\n",
       "      <td>-10.642934</td>\n",
       "      <td>-10.432109</td>\n",
       "      <td>-10.531052</td>\n",
       "      <td>0.137191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 1, 'epsilon': 10}</td>\n",
       "      <td>-10.562007</td>\n",
       "      <td>-11.829240</td>\n",
       "      <td>-8.465385</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.821266</td>\n",
       "      <td>-10.558814</td>\n",
       "      <td>-10.513738</td>\n",
       "      <td>-10.399740</td>\n",
       "      <td>-10.355896</td>\n",
       "      <td>-10.657840</td>\n",
       "      <td>-10.642934</td>\n",
       "      <td>-10.432109</td>\n",
       "      <td>-10.531052</td>\n",
       "      <td>0.137191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 1, 'epsilon': 100}</td>\n",
       "      <td>-10.562007</td>\n",
       "      <td>-11.829240</td>\n",
       "      <td>-8.465385</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.821266</td>\n",
       "      <td>-10.558814</td>\n",
       "      <td>-10.513738</td>\n",
       "      <td>-10.399740</td>\n",
       "      <td>-10.355896</td>\n",
       "      <td>-10.657840</td>\n",
       "      <td>-10.642934</td>\n",
       "      <td>-10.432109</td>\n",
       "      <td>-10.531052</td>\n",
       "      <td>0.137191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.255703</td>\n",
       "      <td>0.017807</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'epsilon': 0.01}</td>\n",
       "      <td>0.613539</td>\n",
       "      <td>0.599819</td>\n",
       "      <td>0.717461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634204</td>\n",
       "      <td>0.655011</td>\n",
       "      <td>0.558993</td>\n",
       "      <td>0.538697</td>\n",
       "      <td>0.598704</td>\n",
       "      <td>0.576222</td>\n",
       "      <td>0.541665</td>\n",
       "      <td>0.600533</td>\n",
       "      <td>0.598368</td>\n",
       "      <td>0.041915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.247802</td>\n",
       "      <td>0.019983</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 10, 'epsilon': 0.1}</td>\n",
       "      <td>0.640232</td>\n",
       "      <td>0.578144</td>\n",
       "      <td>0.740798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.656338</td>\n",
       "      <td>0.618696</td>\n",
       "      <td>0.673033</td>\n",
       "      <td>0.669244</td>\n",
       "      <td>0.642792</td>\n",
       "      <td>0.647346</td>\n",
       "      <td>0.614800</td>\n",
       "      <td>0.659090</td>\n",
       "      <td>0.650474</td>\n",
       "      <td>0.018920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 10, 'epsilon': 1}</td>\n",
       "      <td>-10.562007</td>\n",
       "      <td>-11.829240</td>\n",
       "      <td>-8.465385</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.821266</td>\n",
       "      <td>-10.558814</td>\n",
       "      <td>-10.513738</td>\n",
       "      <td>-10.399740</td>\n",
       "      <td>-10.355896</td>\n",
       "      <td>-10.657840</td>\n",
       "      <td>-10.642934</td>\n",
       "      <td>-10.432109</td>\n",
       "      <td>-10.531052</td>\n",
       "      <td>0.137191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 10, 'epsilon': 10}</td>\n",
       "      <td>-10.562007</td>\n",
       "      <td>-11.829240</td>\n",
       "      <td>-8.465385</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.821266</td>\n",
       "      <td>-10.558814</td>\n",
       "      <td>-10.513738</td>\n",
       "      <td>-10.399740</td>\n",
       "      <td>-10.355896</td>\n",
       "      <td>-10.657840</td>\n",
       "      <td>-10.642934</td>\n",
       "      <td>-10.432109</td>\n",
       "      <td>-10.531052</td>\n",
       "      <td>0.137191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001664</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 10, 'epsilon': 100}</td>\n",
       "      <td>-10.562007</td>\n",
       "      <td>-11.829240</td>\n",
       "      <td>-8.465385</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.821266</td>\n",
       "      <td>-10.558814</td>\n",
       "      <td>-10.513738</td>\n",
       "      <td>-10.399740</td>\n",
       "      <td>-10.355896</td>\n",
       "      <td>-10.657840</td>\n",
       "      <td>-10.642934</td>\n",
       "      <td>-10.432109</td>\n",
       "      <td>-10.531052</td>\n",
       "      <td>0.137191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.267016</td>\n",
       "      <td>0.016030</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 100, 'epsilon': 0.01}</td>\n",
       "      <td>0.556764</td>\n",
       "      <td>0.413102</td>\n",
       "      <td>0.621732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464754</td>\n",
       "      <td>0.114815</td>\n",
       "      <td>0.372286</td>\n",
       "      <td>0.315559</td>\n",
       "      <td>0.375360</td>\n",
       "      <td>0.417336</td>\n",
       "      <td>0.152619</td>\n",
       "      <td>0.426163</td>\n",
       "      <td>0.363159</td>\n",
       "      <td>0.127584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.242793</td>\n",
       "      <td>0.029054</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 100, 'epsilon': 0.1}</td>\n",
       "      <td>0.411534</td>\n",
       "      <td>0.480182</td>\n",
       "      <td>0.696315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605790</td>\n",
       "      <td>0.611090</td>\n",
       "      <td>0.626803</td>\n",
       "      <td>0.595301</td>\n",
       "      <td>0.516362</td>\n",
       "      <td>0.561717</td>\n",
       "      <td>0.540281</td>\n",
       "      <td>0.606725</td>\n",
       "      <td>0.580575</td>\n",
       "      <td>0.037710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 100, 'epsilon': 1}</td>\n",
       "      <td>-10.562007</td>\n",
       "      <td>-11.829240</td>\n",
       "      <td>-8.465385</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.821266</td>\n",
       "      <td>-10.558814</td>\n",
       "      <td>-10.513738</td>\n",
       "      <td>-10.399740</td>\n",
       "      <td>-10.355896</td>\n",
       "      <td>-10.657840</td>\n",
       "      <td>-10.642934</td>\n",
       "      <td>-10.432109</td>\n",
       "      <td>-10.531052</td>\n",
       "      <td>0.137191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.001840</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 100, 'epsilon': 10}</td>\n",
       "      <td>-10.562007</td>\n",
       "      <td>-11.829240</td>\n",
       "      <td>-8.465385</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.821266</td>\n",
       "      <td>-10.558814</td>\n",
       "      <td>-10.513738</td>\n",
       "      <td>-10.399740</td>\n",
       "      <td>-10.355896</td>\n",
       "      <td>-10.657840</td>\n",
       "      <td>-10.642934</td>\n",
       "      <td>-10.432109</td>\n",
       "      <td>-10.531052</td>\n",
       "      <td>0.137191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 100, 'epsilon': 100}</td>\n",
       "      <td>-10.562007</td>\n",
       "      <td>-11.829240</td>\n",
       "      <td>-8.465385</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.821266</td>\n",
       "      <td>-10.558814</td>\n",
       "      <td>-10.513738</td>\n",
       "      <td>-10.399740</td>\n",
       "      <td>-10.355896</td>\n",
       "      <td>-10.657840</td>\n",
       "      <td>-10.642934</td>\n",
       "      <td>-10.432109</td>\n",
       "      <td>-10.531052</td>\n",
       "      <td>0.137191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.004972      0.000818         0.000722        0.000397    0.01   \n",
       "1        0.006087      0.001446         0.000830        0.000431    0.01   \n",
       "2        0.001592      0.000495         0.001301        0.000453    0.01   \n",
       "3        0.001822      0.000402         0.001030        0.000646    0.01   \n",
       "4        0.001097      0.000299         0.001109        0.000223    0.01   \n",
       "5        0.044006      0.008296         0.001453        0.001704     0.1   \n",
       "6        0.046222      0.018398         0.000962        0.000650     0.1   \n",
       "7        0.001310      0.000450         0.001307        0.000458     0.1   \n",
       "8        0.001605      0.000488         0.000893        0.000527     0.1   \n",
       "9        0.001650      0.000532         0.001138        0.000447     0.1   \n",
       "10       0.160484      0.017751         0.001230        0.000560       1   \n",
       "11       0.175263      0.015393         0.001215        0.000399       1   \n",
       "12       0.001435      0.000533         0.001074        0.000190       1   \n",
       "13       0.001600      0.000466         0.001289        0.000508       1   \n",
       "14       0.002262      0.001948         0.001191        0.000421       1   \n",
       "15       0.255703      0.017807         0.001205        0.000415      10   \n",
       "16       0.247802      0.019983         0.001224        0.000414      10   \n",
       "17       0.001606      0.000491         0.001079        0.000307      10   \n",
       "18       0.001440      0.000439         0.001252        0.000518      10   \n",
       "19       0.001664      0.000398         0.001036        0.000366      10   \n",
       "20       0.267016      0.016030         0.001266        0.000398     100   \n",
       "21       0.242793      0.029054         0.000990        0.000448     100   \n",
       "22       0.001536      0.000566         0.000798        0.000599     100   \n",
       "23       0.001840      0.000310         0.001087        0.000549     100   \n",
       "24       0.001524      0.000536         0.001087        0.000555     100   \n",
       "\n",
       "   param_epsilon                        params  split0_test_score  \\\n",
       "0           0.01  {'C': 0.01, 'epsilon': 0.01}           0.684228   \n",
       "1            0.1   {'C': 0.01, 'epsilon': 0.1}           0.677519   \n",
       "2              1     {'C': 0.01, 'epsilon': 1}         -10.562007   \n",
       "3             10    {'C': 0.01, 'epsilon': 10}         -10.562007   \n",
       "4            100   {'C': 0.01, 'epsilon': 100}         -10.562007   \n",
       "5           0.01   {'C': 0.1, 'epsilon': 0.01}           0.682835   \n",
       "6            0.1    {'C': 0.1, 'epsilon': 0.1}           0.678101   \n",
       "7              1      {'C': 0.1, 'epsilon': 1}         -10.562007   \n",
       "8             10     {'C': 0.1, 'epsilon': 10}         -10.562007   \n",
       "9            100    {'C': 0.1, 'epsilon': 100}         -10.562007   \n",
       "10          0.01     {'C': 1, 'epsilon': 0.01}           0.685693   \n",
       "11           0.1      {'C': 1, 'epsilon': 0.1}           0.676927   \n",
       "12             1        {'C': 1, 'epsilon': 1}         -10.562007   \n",
       "13            10       {'C': 1, 'epsilon': 10}         -10.562007   \n",
       "14           100      {'C': 1, 'epsilon': 100}         -10.562007   \n",
       "15          0.01    {'C': 10, 'epsilon': 0.01}           0.613539   \n",
       "16           0.1     {'C': 10, 'epsilon': 0.1}           0.640232   \n",
       "17             1       {'C': 10, 'epsilon': 1}         -10.562007   \n",
       "18            10      {'C': 10, 'epsilon': 10}         -10.562007   \n",
       "19           100     {'C': 10, 'epsilon': 100}         -10.562007   \n",
       "20          0.01   {'C': 100, 'epsilon': 0.01}           0.556764   \n",
       "21           0.1    {'C': 100, 'epsilon': 0.1}           0.411534   \n",
       "22             1      {'C': 100, 'epsilon': 1}         -10.562007   \n",
       "23            10     {'C': 100, 'epsilon': 10}         -10.562007   \n",
       "24           100    {'C': 100, 'epsilon': 100}         -10.562007   \n",
       "\n",
       "    split1_test_score  split2_test_score  ...  split2_train_score  \\\n",
       "0            0.609148           0.751710  ...            0.683043   \n",
       "1            0.605177           0.748425  ...            0.682220   \n",
       "2          -11.829240          -8.465385  ...          -10.821266   \n",
       "3          -11.829240          -8.465385  ...          -10.821266   \n",
       "4          -11.829240          -8.465385  ...          -10.821266   \n",
       "5            0.609998           0.757065  ...            0.682932   \n",
       "6            0.611903           0.757334  ...            0.685222   \n",
       "7          -11.829240          -8.465385  ...          -10.821266   \n",
       "8          -11.829240          -8.465385  ...          -10.821266   \n",
       "9          -11.829240          -8.465385  ...          -10.821266   \n",
       "10           0.608131           0.759070  ...            0.680484   \n",
       "11           0.607622           0.757675  ...            0.683756   \n",
       "12         -11.829240          -8.465385  ...          -10.821266   \n",
       "13         -11.829240          -8.465385  ...          -10.821266   \n",
       "14         -11.829240          -8.465385  ...          -10.821266   \n",
       "15           0.599819           0.717461  ...            0.634204   \n",
       "16           0.578144           0.740798  ...            0.656338   \n",
       "17         -11.829240          -8.465385  ...          -10.821266   \n",
       "18         -11.829240          -8.465385  ...          -10.821266   \n",
       "19         -11.829240          -8.465385  ...          -10.821266   \n",
       "20           0.413102           0.621732  ...            0.464754   \n",
       "21           0.480182           0.696315  ...            0.605790   \n",
       "22         -11.829240          -8.465385  ...          -10.821266   \n",
       "23         -11.829240          -8.465385  ...          -10.821266   \n",
       "24         -11.829240          -8.465385  ...          -10.821266   \n",
       "\n",
       "    split3_train_score  split4_train_score  split5_train_score  \\\n",
       "0             0.695891            0.689057            0.698055   \n",
       "1             0.695473            0.688364            0.696216   \n",
       "2           -10.558814          -10.513738          -10.399740   \n",
       "3           -10.558814          -10.513738          -10.399740   \n",
       "4           -10.558814          -10.513738          -10.399740   \n",
       "5             0.695794            0.689074            0.697641   \n",
       "6             0.697605            0.691330            0.699895   \n",
       "7           -10.558814          -10.513738          -10.399740   \n",
       "8           -10.558814          -10.513738          -10.399740   \n",
       "9           -10.558814          -10.513738          -10.399740   \n",
       "10            0.692493            0.688583            0.694825   \n",
       "11            0.696778            0.691061            0.698690   \n",
       "12          -10.558814          -10.513738          -10.399740   \n",
       "13          -10.558814          -10.513738          -10.399740   \n",
       "14          -10.558814          -10.513738          -10.399740   \n",
       "15            0.655011            0.558993            0.538697   \n",
       "16            0.618696            0.673033            0.669244   \n",
       "17          -10.558814          -10.513738          -10.399740   \n",
       "18          -10.558814          -10.513738          -10.399740   \n",
       "19          -10.558814          -10.513738          -10.399740   \n",
       "20            0.114815            0.372286            0.315559   \n",
       "21            0.611090            0.626803            0.595301   \n",
       "22          -10.558814          -10.513738          -10.399740   \n",
       "23          -10.558814          -10.513738          -10.399740   \n",
       "24          -10.558814          -10.513738          -10.399740   \n",
       "\n",
       "    split6_train_score  split7_train_score  split8_train_score  \\\n",
       "0             0.694044            0.688142            0.687181   \n",
       "1             0.693590            0.687927            0.686750   \n",
       "2           -10.355896          -10.657840          -10.642934   \n",
       "3           -10.355896          -10.657840          -10.642934   \n",
       "4           -10.355896          -10.657840          -10.642934   \n",
       "5             0.694499            0.687884            0.687125   \n",
       "6             0.696579            0.690786            0.689518   \n",
       "7           -10.355896          -10.657840          -10.642934   \n",
       "8           -10.355896          -10.657840          -10.642934   \n",
       "9           -10.355896          -10.657840          -10.642934   \n",
       "10            0.692675            0.687827            0.683331   \n",
       "11            0.695592            0.690382            0.688441   \n",
       "12          -10.355896          -10.657840          -10.642934   \n",
       "13          -10.355896          -10.657840          -10.642934   \n",
       "14          -10.355896          -10.657840          -10.642934   \n",
       "15            0.598704            0.576222            0.541665   \n",
       "16            0.642792            0.647346            0.614800   \n",
       "17          -10.355896          -10.657840          -10.642934   \n",
       "18          -10.355896          -10.657840          -10.642934   \n",
       "19          -10.355896          -10.657840          -10.642934   \n",
       "20            0.375360            0.417336            0.152619   \n",
       "21            0.516362            0.561717            0.540281   \n",
       "22          -10.355896          -10.657840          -10.642934   \n",
       "23          -10.355896          -10.657840          -10.642934   \n",
       "24          -10.355896          -10.657840          -10.642934   \n",
       "\n",
       "    split9_train_score  mean_train_score  std_train_score  \n",
       "0             0.697096          0.692741         0.005382  \n",
       "1             0.696642          0.692001         0.005240  \n",
       "2           -10.432109        -10.531052         0.137191  \n",
       "3           -10.432109        -10.531052         0.137191  \n",
       "4           -10.432109        -10.531052         0.137191  \n",
       "5             0.697161          0.692699         0.005437  \n",
       "6             0.699497          0.694924         0.005248  \n",
       "7           -10.432109        -10.531052         0.137191  \n",
       "8           -10.432109        -10.531052         0.137191  \n",
       "9           -10.432109        -10.531052         0.137191  \n",
       "10            0.696750          0.691214         0.005882  \n",
       "11            0.696006          0.693768         0.005073  \n",
       "12          -10.432109        -10.531052         0.137191  \n",
       "13          -10.432109        -10.531052         0.137191  \n",
       "14          -10.432109        -10.531052         0.137191  \n",
       "15            0.600533          0.598368         0.041915  \n",
       "16            0.659090          0.650474         0.018920  \n",
       "17          -10.432109        -10.531052         0.137191  \n",
       "18          -10.432109        -10.531052         0.137191  \n",
       "19          -10.432109        -10.531052         0.137191  \n",
       "20            0.426163          0.363159         0.127584  \n",
       "21            0.606725          0.580575         0.037710  \n",
       "22          -10.432109        -10.531052         0.137191  \n",
       "23          -10.432109        -10.531052         0.137191  \n",
       "24          -10.432109        -10.531052         0.137191  \n",
       "\n",
       "[25 rows x 32 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_linearsvr = pd.DataFrame(grid_svrl.cv_results_)\n",
    "result_linearsvr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee50cb6390>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee50cb6748>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x1ee50c595c0>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50c61518>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50c613c8>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50cb6dd8>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50cbf2b0>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50cbf780>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50cbfc88>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50cc9198>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50cc9668>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50cc9b38>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50ccf0b8>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50cc97b8>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50cbfc50>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50cbf5f8>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50ccf8d0>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50ccfd30>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50cd62b0>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50cd6780>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50cd6c50>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50ce1198>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50ce1630>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50cd6828>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50cb6be0>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50ce1a20>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50ce1240>],\n",
       " <a list of 25 Text xticklabel objects>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee50cb6860>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee50aad4e0>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ee50cef668>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Alpha')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(result_linearsvr.shape[0]), result_linearsvr['mean_train_score'], label = 'mean train score')\n",
    "plt.plot(range(result_linearsvr.shape[0]), result_linearsvr['mean_test_score'], label = 'mean test score')\n",
    "plt.xticks(range(result_linearsvr.shape[0]), result_linearsvr['param_C'], rotation = 90)\n",
    "plt.plot([grid_svrl.best_index_], result_linearsvr['mean_train_score'][grid_svrl.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.plot([grid_svrl.best_index_], result_linearsvr['mean_test_score'][grid_svrl.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('Alpha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVR Summary:\n",
    "\n",
    "#### Train Score: 0.6948\n",
    "\n",
    "#### Test Score: 0.6803\n",
    "\n",
    "#### Best Parameters: {'C': 0.1, 'epsilon': 0.1}\n",
    "\n",
    "#### Best Cross - Validation Score: 0.6867\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR with Kernel 'Linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parms_linear = {'C': [0.01,0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_linear = SVR(kernel='linear')\n",
    "grid_svr_linear = GridSearchCV(estimator = svr_linear,param_grid = grid_parms_linear,return_train_score=True,n_jobs= -1,cv=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6, error_score='raise-deprecating',\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='auto_deprecated',\n",
       "                           kernel='linear', max_iter=-1, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=-1, param_grid={'C': [0.01, 0.1, 1, 10, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svr_linear.fit(X_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.01}\n",
      "Best cross-validation score: 0.6899\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_svr_linear.best_params_))\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid_svr_linear.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=100, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "    gamma='auto_deprecated', kernel='linear', max_iter=-1, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6947399660544613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6801070541465106"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr = SVR(kernel = 'linear',C = 100)\n",
    "        \n",
    "        #train the model\n",
    "svr.fit(X_train_pca, y_train)\n",
    "        \n",
    "        #evaluate the model\n",
    "print(svr.score(X_train_pca, y_train))\n",
    "svr_test_score = svr.score(X_test_pca, y_test)\n",
    "svr_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[0.65766366 0.70855705 0.6969277  0.68598263 0.72559424 0.66280935]\n",
      "0.6895891050826931\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "kfold = KFold(n_splits=6)\n",
    "print(\"Cross-validation scores:\\n{}\".format(cross_val_score(svr , X_train_pca, y_train, cv=kfold)))\n",
    "scores = cross_val_score(svr , X_train_pca, y_train, cv=kfold)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.080769</td>\n",
       "      <td>0.019168</td>\n",
       "      <td>0.005298</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.657446</td>\n",
       "      <td>0.708318</td>\n",
       "      <td>0.698379</td>\n",
       "      <td>0.686100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024080</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700408</td>\n",
       "      <td>0.690850</td>\n",
       "      <td>0.694316</td>\n",
       "      <td>0.696545</td>\n",
       "      <td>0.688417</td>\n",
       "      <td>0.700171</td>\n",
       "      <td>0.695118</td>\n",
       "      <td>0.004460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.238054</td>\n",
       "      <td>0.028930</td>\n",
       "      <td>0.005519</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.657651</td>\n",
       "      <td>0.708209</td>\n",
       "      <td>0.697002</td>\n",
       "      <td>0.685917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023973</td>\n",
       "      <td>4</td>\n",
       "      <td>0.700392</td>\n",
       "      <td>0.690577</td>\n",
       "      <td>0.694332</td>\n",
       "      <td>0.696602</td>\n",
       "      <td>0.688503</td>\n",
       "      <td>0.700447</td>\n",
       "      <td>0.695142</td>\n",
       "      <td>0.004535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.034371</td>\n",
       "      <td>0.109331</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.657859</td>\n",
       "      <td>0.708477</td>\n",
       "      <td>0.697072</td>\n",
       "      <td>0.685971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023944</td>\n",
       "      <td>2</td>\n",
       "      <td>0.700357</td>\n",
       "      <td>0.690586</td>\n",
       "      <td>0.694407</td>\n",
       "      <td>0.696648</td>\n",
       "      <td>0.688545</td>\n",
       "      <td>0.700489</td>\n",
       "      <td>0.695172</td>\n",
       "      <td>0.004525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.335639</td>\n",
       "      <td>0.322377</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.658171</td>\n",
       "      <td>0.708339</td>\n",
       "      <td>0.696906</td>\n",
       "      <td>0.685927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023837</td>\n",
       "      <td>3</td>\n",
       "      <td>0.700386</td>\n",
       "      <td>0.690548</td>\n",
       "      <td>0.694384</td>\n",
       "      <td>0.696648</td>\n",
       "      <td>0.688485</td>\n",
       "      <td>0.700487</td>\n",
       "      <td>0.695156</td>\n",
       "      <td>0.004552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.760736</td>\n",
       "      <td>1.946701</td>\n",
       "      <td>0.004790</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>0.657664</td>\n",
       "      <td>0.708557</td>\n",
       "      <td>0.696928</td>\n",
       "      <td>0.685983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024012</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700333</td>\n",
       "      <td>0.690598</td>\n",
       "      <td>0.694405</td>\n",
       "      <td>0.696650</td>\n",
       "      <td>0.688422</td>\n",
       "      <td>0.700397</td>\n",
       "      <td>0.695134</td>\n",
       "      <td>0.004531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.080769      0.019168         0.005298        0.000487    0.01   \n",
       "1       0.238054      0.028930         0.005519        0.000489     0.1   \n",
       "2       1.034371      0.109331         0.004920        0.000529       1   \n",
       "3       6.335639      0.322377         0.005828        0.000377      10   \n",
       "4      44.760736      1.946701         0.004790        0.000677     100   \n",
       "\n",
       "        params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'C': 0.01}           0.657446           0.708318           0.698379   \n",
       "1   {'C': 0.1}           0.657651           0.708209           0.697002   \n",
       "2     {'C': 1}           0.657859           0.708477           0.697072   \n",
       "3    {'C': 10}           0.658171           0.708339           0.696906   \n",
       "4   {'C': 100}           0.657664           0.708557           0.696928   \n",
       "\n",
       "   split3_test_score  ...  std_test_score  rank_test_score  \\\n",
       "0           0.686100  ...        0.024080                1   \n",
       "1           0.685917  ...        0.023973                4   \n",
       "2           0.685971  ...        0.023944                2   \n",
       "3           0.685927  ...        0.023837                3   \n",
       "4           0.685983  ...        0.024012                5   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.700408            0.690850            0.694316   \n",
       "1            0.700392            0.690577            0.694332   \n",
       "2            0.700357            0.690586            0.694407   \n",
       "3            0.700386            0.690548            0.694384   \n",
       "4            0.700333            0.690598            0.694405   \n",
       "\n",
       "   split3_train_score  split4_train_score  split5_train_score  \\\n",
       "0            0.696545            0.688417            0.700171   \n",
       "1            0.696602            0.688503            0.700447   \n",
       "2            0.696648            0.688545            0.700489   \n",
       "3            0.696648            0.688485            0.700487   \n",
       "4            0.696650            0.688422            0.700397   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.695118         0.004460  \n",
       "1          0.695142         0.004535  \n",
       "2          0.695172         0.004525  \n",
       "3          0.695156         0.004552  \n",
       "4          0.695134         0.004531  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_svr_linear = pd.DataFrame(grid_svr_linear.cv_results_)\n",
    "result_svr_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee50d4b358>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee50d4bb70>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x1ee50d38dd8>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50d2ac88>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50c515c0>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50d5b1d0>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50d5b6d8>],\n",
       " <a list of 5 Text xticklabel objects>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee50d4beb8>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee50a1de10>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ee50d62518>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'C')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(result_svr_linear.shape[0]), result_svr_linear['mean_train_score'], label = 'mean train score')\n",
    "plt.plot(range(result_svr_linear.shape[0]), result_svr_linear['mean_test_score'], label = 'mean test score')\n",
    "plt.xticks(range(result_svr_linear.shape[0]), result_svr_linear['param_C'], rotation = 90)\n",
    "plt.plot([grid_svr_linear.best_index_], result_svr_linear['mean_train_score'][grid_svr_linear.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.plot([grid_svr_linear.best_index_], result_svr_linear['mean_test_score'][grid_svr_linear.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR with Kernel 'Linear' Summary:\n",
    "\n",
    "#### Train Score: 0.6947\n",
    "\n",
    "#### Test Score: 0.6801\n",
    "\n",
    "#### Best Parameters: {'C' : 0.01}\n",
    "\n",
    "#### Best Cross - Validation Score: 0.6899"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR with Kernel 'Poly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parms_svrp = {'C': [1, 10, 100],'degree':[1,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_poly = SVR(kernel='poly')\n",
    "grid_svr_poly = GridSearchCV(estimator = svr_poly,param_grid = grid_parms_svrp,return_train_score=True,n_jobs= -1,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='auto_deprecated', kernel='poly',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [1, 10, 100], 'degree': [1, 3]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svr_poly.fit(X_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1, 'degree': 1}\n",
      "Best cross-validation score: 0.6891\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_degree</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.103663</td>\n",
       "      <td>0.035745</td>\n",
       "      <td>0.006615</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1, 'degree': 1}</td>\n",
       "      <td>0.682567</td>\n",
       "      <td>0.690655</td>\n",
       "      <td>0.694203</td>\n",
       "      <td>0.689142</td>\n",
       "      <td>0.004870</td>\n",
       "      <td>1</td>\n",
       "      <td>0.696395</td>\n",
       "      <td>0.696349</td>\n",
       "      <td>0.694592</td>\n",
       "      <td>0.695779</td>\n",
       "      <td>0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.368321</td>\n",
       "      <td>0.071603</td>\n",
       "      <td>0.011324</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'C': 1, 'degree': 3}</td>\n",
       "      <td>0.309821</td>\n",
       "      <td>0.318693</td>\n",
       "      <td>-0.029289</td>\n",
       "      <td>0.199742</td>\n",
       "      <td>0.161990</td>\n",
       "      <td>4</td>\n",
       "      <td>0.777762</td>\n",
       "      <td>0.766003</td>\n",
       "      <td>0.773397</td>\n",
       "      <td>0.772387</td>\n",
       "      <td>0.004853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.620735</td>\n",
       "      <td>0.036334</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 10, 'degree': 1}</td>\n",
       "      <td>0.682022</td>\n",
       "      <td>0.690603</td>\n",
       "      <td>0.694161</td>\n",
       "      <td>0.688928</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>3</td>\n",
       "      <td>0.696258</td>\n",
       "      <td>0.696298</td>\n",
       "      <td>0.694568</td>\n",
       "      <td>0.695708</td>\n",
       "      <td>0.000807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.995787</td>\n",
       "      <td>0.264079</td>\n",
       "      <td>0.013313</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>{'C': 10, 'degree': 3}</td>\n",
       "      <td>-0.179353</td>\n",
       "      <td>-0.202416</td>\n",
       "      <td>-6.328244</td>\n",
       "      <td>-2.236671</td>\n",
       "      <td>2.893194</td>\n",
       "      <td>5</td>\n",
       "      <td>0.782029</td>\n",
       "      <td>0.773749</td>\n",
       "      <td>0.781357</td>\n",
       "      <td>0.779045</td>\n",
       "      <td>0.003755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.937589</td>\n",
       "      <td>0.196495</td>\n",
       "      <td>0.008166</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 100, 'degree': 1}</td>\n",
       "      <td>0.682338</td>\n",
       "      <td>0.690438</td>\n",
       "      <td>0.694228</td>\n",
       "      <td>0.689001</td>\n",
       "      <td>0.004959</td>\n",
       "      <td>2</td>\n",
       "      <td>0.696315</td>\n",
       "      <td>0.696262</td>\n",
       "      <td>0.694630</td>\n",
       "      <td>0.695736</td>\n",
       "      <td>0.000782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>75.115580</td>\n",
       "      <td>1.994058</td>\n",
       "      <td>0.012173</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>{'C': 100, 'degree': 3}</td>\n",
       "      <td>-1.566335</td>\n",
       "      <td>-0.805437</td>\n",
       "      <td>-16.937669</td>\n",
       "      <td>-6.436480</td>\n",
       "      <td>7.431956</td>\n",
       "      <td>6</td>\n",
       "      <td>0.780452</td>\n",
       "      <td>0.773178</td>\n",
       "      <td>0.782151</td>\n",
       "      <td>0.778593</td>\n",
       "      <td>0.003892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.103663      0.035745         0.006615        0.001017       1   \n",
       "1       0.368321      0.071603         0.011324        0.001241       1   \n",
       "2       0.620735      0.036334         0.007655        0.001224      10   \n",
       "3       5.995787      0.264079         0.013313        0.001060      10   \n",
       "4       4.937589      0.196495         0.008166        0.001453     100   \n",
       "5      75.115580      1.994058         0.012173        0.002968     100   \n",
       "\n",
       "  param_degree                   params  split0_test_score  split1_test_score  \\\n",
       "0            1    {'C': 1, 'degree': 1}           0.682567           0.690655   \n",
       "1            3    {'C': 1, 'degree': 3}           0.309821           0.318693   \n",
       "2            1   {'C': 10, 'degree': 1}           0.682022           0.690603   \n",
       "3            3   {'C': 10, 'degree': 3}          -0.179353          -0.202416   \n",
       "4            1  {'C': 100, 'degree': 1}           0.682338           0.690438   \n",
       "5            3  {'C': 100, 'degree': 3}          -1.566335          -0.805437   \n",
       "\n",
       "   split2_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           0.694203         0.689142        0.004870                1   \n",
       "1          -0.029289         0.199742        0.161990                4   \n",
       "2           0.694161         0.688928        0.005095                3   \n",
       "3          -6.328244        -2.236671        2.893194                5   \n",
       "4           0.694228         0.689001        0.004959                2   \n",
       "5         -16.937669        -6.436480        7.431956                6   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.696395            0.696349            0.694592   \n",
       "1            0.777762            0.766003            0.773397   \n",
       "2            0.696258            0.696298            0.694568   \n",
       "3            0.782029            0.773749            0.781357   \n",
       "4            0.696315            0.696262            0.694630   \n",
       "5            0.780452            0.773178            0.782151   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.695779         0.000839  \n",
       "1          0.772387         0.004853  \n",
       "2          0.695708         0.000807  \n",
       "3          0.779045         0.003755  \n",
       "4          0.695736         0.000782  \n",
       "5          0.778593         0.003892  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_svr_poly.best_params_))\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid_svr_poly.best_score_))\n",
    "pd.DataFrame(grid_svr_poly.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=100, cache_size=200, coef0=0.0, degree=1, epsilon=0.1,\n",
       "    gamma='auto_deprecated', kernel='poly', max_iter=-1, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6948087842105182"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6800778869836632"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_p = SVR(kernel='poly',C=100,degree = 1)\n",
    "svr_p.fit(X_train_pca, y_train)\n",
    "svr_p.score(X_train_pca, y_train)\n",
    "svrp_test_score = svr_p.score(X_test_pca, y_test)\n",
    "svrp_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[0.65721761 0.70856763 0.69712583 0.68597541 0.72571079 0.6630408 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6896063446975841\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#scores = cross_val_score(logreg, iris.data, iris.target)\n",
    "kfold = KFold(n_splits=6)\n",
    "print(\"Cross-validation scores:\\n{}\".format(cross_val_score(svr_p, X_train_pca, y_train, cv=kfold)))\n",
    "scores = cross_val_score(svr_p, X_train_pca, y_train, cv=kfold)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_degree</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.103663</td>\n",
       "      <td>0.035745</td>\n",
       "      <td>0.006615</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1, 'degree': 1}</td>\n",
       "      <td>0.682567</td>\n",
       "      <td>0.690655</td>\n",
       "      <td>0.694203</td>\n",
       "      <td>0.689142</td>\n",
       "      <td>0.004870</td>\n",
       "      <td>1</td>\n",
       "      <td>0.696395</td>\n",
       "      <td>0.696349</td>\n",
       "      <td>0.694592</td>\n",
       "      <td>0.695779</td>\n",
       "      <td>0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.368321</td>\n",
       "      <td>0.071603</td>\n",
       "      <td>0.011324</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'C': 1, 'degree': 3}</td>\n",
       "      <td>0.309821</td>\n",
       "      <td>0.318693</td>\n",
       "      <td>-0.029289</td>\n",
       "      <td>0.199742</td>\n",
       "      <td>0.161990</td>\n",
       "      <td>4</td>\n",
       "      <td>0.777762</td>\n",
       "      <td>0.766003</td>\n",
       "      <td>0.773397</td>\n",
       "      <td>0.772387</td>\n",
       "      <td>0.004853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.620735</td>\n",
       "      <td>0.036334</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 10, 'degree': 1}</td>\n",
       "      <td>0.682022</td>\n",
       "      <td>0.690603</td>\n",
       "      <td>0.694161</td>\n",
       "      <td>0.688928</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>3</td>\n",
       "      <td>0.696258</td>\n",
       "      <td>0.696298</td>\n",
       "      <td>0.694568</td>\n",
       "      <td>0.695708</td>\n",
       "      <td>0.000807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.995787</td>\n",
       "      <td>0.264079</td>\n",
       "      <td>0.013313</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>{'C': 10, 'degree': 3}</td>\n",
       "      <td>-0.179353</td>\n",
       "      <td>-0.202416</td>\n",
       "      <td>-6.328244</td>\n",
       "      <td>-2.236671</td>\n",
       "      <td>2.893194</td>\n",
       "      <td>5</td>\n",
       "      <td>0.782029</td>\n",
       "      <td>0.773749</td>\n",
       "      <td>0.781357</td>\n",
       "      <td>0.779045</td>\n",
       "      <td>0.003755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.937589</td>\n",
       "      <td>0.196495</td>\n",
       "      <td>0.008166</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 100, 'degree': 1}</td>\n",
       "      <td>0.682338</td>\n",
       "      <td>0.690438</td>\n",
       "      <td>0.694228</td>\n",
       "      <td>0.689001</td>\n",
       "      <td>0.004959</td>\n",
       "      <td>2</td>\n",
       "      <td>0.696315</td>\n",
       "      <td>0.696262</td>\n",
       "      <td>0.694630</td>\n",
       "      <td>0.695736</td>\n",
       "      <td>0.000782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>75.115580</td>\n",
       "      <td>1.994058</td>\n",
       "      <td>0.012173</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>{'C': 100, 'degree': 3}</td>\n",
       "      <td>-1.566335</td>\n",
       "      <td>-0.805437</td>\n",
       "      <td>-16.937669</td>\n",
       "      <td>-6.436480</td>\n",
       "      <td>7.431956</td>\n",
       "      <td>6</td>\n",
       "      <td>0.780452</td>\n",
       "      <td>0.773178</td>\n",
       "      <td>0.782151</td>\n",
       "      <td>0.778593</td>\n",
       "      <td>0.003892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.103663      0.035745         0.006615        0.001017       1   \n",
       "1       0.368321      0.071603         0.011324        0.001241       1   \n",
       "2       0.620735      0.036334         0.007655        0.001224      10   \n",
       "3       5.995787      0.264079         0.013313        0.001060      10   \n",
       "4       4.937589      0.196495         0.008166        0.001453     100   \n",
       "5      75.115580      1.994058         0.012173        0.002968     100   \n",
       "\n",
       "  param_degree                   params  split0_test_score  split1_test_score  \\\n",
       "0            1    {'C': 1, 'degree': 1}           0.682567           0.690655   \n",
       "1            3    {'C': 1, 'degree': 3}           0.309821           0.318693   \n",
       "2            1   {'C': 10, 'degree': 1}           0.682022           0.690603   \n",
       "3            3   {'C': 10, 'degree': 3}          -0.179353          -0.202416   \n",
       "4            1  {'C': 100, 'degree': 1}           0.682338           0.690438   \n",
       "5            3  {'C': 100, 'degree': 3}          -1.566335          -0.805437   \n",
       "\n",
       "   split2_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0           0.694203         0.689142        0.004870                1   \n",
       "1          -0.029289         0.199742        0.161990                4   \n",
       "2           0.694161         0.688928        0.005095                3   \n",
       "3          -6.328244        -2.236671        2.893194                5   \n",
       "4           0.694228         0.689001        0.004959                2   \n",
       "5         -16.937669        -6.436480        7.431956                6   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0            0.696395            0.696349            0.694592   \n",
       "1            0.777762            0.766003            0.773397   \n",
       "2            0.696258            0.696298            0.694568   \n",
       "3            0.782029            0.773749            0.781357   \n",
       "4            0.696315            0.696262            0.694630   \n",
       "5            0.780452            0.773178            0.782151   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.695779         0.000839  \n",
       "1          0.772387         0.004853  \n",
       "2          0.695708         0.000807  \n",
       "3          0.779045         0.003755  \n",
       "4          0.695736         0.000782  \n",
       "5          0.778593         0.003892  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_svr_poly= pd.DataFrame(grid_svr_poly.cv_results_)\n",
    "result_svr_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee50dd3d30>]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee50d91588>]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x1ee50dba358>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50db1c88>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50db1898>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50ddf198>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50ddfeb8>,\n",
       "  <matplotlib.axis.XTick at 0x1ee50de7400>],\n",
       " <a list of 6 Text xticklabel objects>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee50ddf550>]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee50de7e48>]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ee50de75c0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(result_svr_poly.shape[0]), result_svr_poly['mean_train_score'], label = 'mean train score')\n",
    "plt.plot(range(result_svr_poly.shape[0]), result_svr_poly['mean_test_score'], label = 'mean test score')\n",
    "plt.xticks(range(result_svr_poly.shape[0]), result_svr_poly['param_C'], rotation = 90)\n",
    "plt.plot([grid_svr_poly.best_index_], result_svr_poly['mean_train_score'][grid_svr_poly.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.plot([grid_svr_poly.best_index_], result_svr_poly['mean_test_score'][grid_svr_poly.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR with Kernel 'Poly' Summary:\n",
    "\n",
    "#### Train Score: 0.6948\n",
    "\n",
    "#### Test Score: 0.6801\n",
    "\n",
    "#### Best Parameters: {'C': 1, 'degree': 1}\n",
    "\n",
    "#### Best Cross - Validation Score: 0.6891"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR with Kernel 'rbf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parms_rbf = {'C': [0.1, 1, 10, 100],'gamma':[0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf = SVR(kernel='rbf')\n",
    "grid_svr_rbf = GridSearchCV(estimator = svr_rbf,param_grid = grid_parms_rbf,return_train_score=True,n_jobs= -1,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='auto_deprecated', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'gamma': [0.1, 1, 10, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svr_rbf.fit(X_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1, 'gamma': 0.1}\n",
      "Best cross-validation score: 0.6637\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_svr_rbf.best_params_))\n",
    "print(\"Best cross-validation score: {:.4f}\".format(grid_svr_rbf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=100, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.1,\n",
       "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8600747140301671"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5393493958278313"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rbf = SVR(kernel='rbf',C=100,gamma=0.1)\n",
    "svr_rbf.fit(X_train_pca, y_train)\n",
    "svr_rbf.score(X_train_pca, y_train)\n",
    "svr_rbf_test_score = svr_rbf.score(X_test_pca, y_test)\n",
    "svr_rbf_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[0.61101697 0.62841202 0.59188209 0.58989257 0.59973473 0.59099321]\n",
      "0.6019885963246779\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "kfold = KFold(n_splits=6)\n",
    "print(\"Cross-validation scores:\\n{}\".format(cross_val_score(svr_rbf, X_train_pca, y_train, cv=kfold)))\n",
    "scores = cross_val_score(svr_rbf, X_train_pca, y_train, cv=kfold)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058465</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.014301</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.1}</td>\n",
       "      <td>0.643627</td>\n",
       "      <td>0.654478</td>\n",
       "      <td>0.647687</td>\n",
       "      <td>0.648597</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>2</td>\n",
       "      <td>0.747270</td>\n",
       "      <td>0.747831</td>\n",
       "      <td>0.743444</td>\n",
       "      <td>0.746182</td>\n",
       "      <td>0.001950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.092396</td>\n",
       "      <td>0.013784</td>\n",
       "      <td>0.030649</td>\n",
       "      <td>0.005806</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.1, 'gamma': 1}</td>\n",
       "      <td>0.077404</td>\n",
       "      <td>0.082293</td>\n",
       "      <td>0.067362</td>\n",
       "      <td>0.075686</td>\n",
       "      <td>0.006215</td>\n",
       "      <td>8</td>\n",
       "      <td>0.504675</td>\n",
       "      <td>0.493443</td>\n",
       "      <td>0.504388</td>\n",
       "      <td>0.500835</td>\n",
       "      <td>0.005228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.112345</td>\n",
       "      <td>0.012555</td>\n",
       "      <td>0.022735</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 0.1, 'gamma': 10}</td>\n",
       "      <td>-0.000727</td>\n",
       "      <td>-0.000383</td>\n",
       "      <td>-0.015475</td>\n",
       "      <td>-0.005528</td>\n",
       "      <td>0.007035</td>\n",
       "      <td>9</td>\n",
       "      <td>0.473397</td>\n",
       "      <td>0.454660</td>\n",
       "      <td>0.467935</td>\n",
       "      <td>0.465331</td>\n",
       "      <td>0.007868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159410</td>\n",
       "      <td>0.010241</td>\n",
       "      <td>0.050031</td>\n",
       "      <td>0.003737</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 0.1, 'gamma': 100}</td>\n",
       "      <td>-0.001676</td>\n",
       "      <td>-0.001624</td>\n",
       "      <td>-0.015465</td>\n",
       "      <td>-0.006255</td>\n",
       "      <td>0.006512</td>\n",
       "      <td>13</td>\n",
       "      <td>0.473200</td>\n",
       "      <td>0.454666</td>\n",
       "      <td>0.467520</td>\n",
       "      <td>0.465129</td>\n",
       "      <td>0.007753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.118071</td>\n",
       "      <td>0.008566</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1}</td>\n",
       "      <td>0.658039</td>\n",
       "      <td>0.659721</td>\n",
       "      <td>0.673304</td>\n",
       "      <td>0.663688</td>\n",
       "      <td>0.006834</td>\n",
       "      <td>1</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.846661</td>\n",
       "      <td>0.844749</td>\n",
       "      <td>0.843179</td>\n",
       "      <td>0.003656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.108773</td>\n",
       "      <td>0.017845</td>\n",
       "      <td>0.027454</td>\n",
       "      <td>0.006283</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1, 'gamma': 1}</td>\n",
       "      <td>0.125634</td>\n",
       "      <td>0.118724</td>\n",
       "      <td>0.127941</td>\n",
       "      <td>0.124100</td>\n",
       "      <td>0.003916</td>\n",
       "      <td>5</td>\n",
       "      <td>0.825999</td>\n",
       "      <td>0.829066</td>\n",
       "      <td>0.830193</td>\n",
       "      <td>0.828420</td>\n",
       "      <td>0.001772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.112883</td>\n",
       "      <td>0.010936</td>\n",
       "      <td>0.026524</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 1, 'gamma': 10}</td>\n",
       "      <td>-0.004696</td>\n",
       "      <td>-0.010390</td>\n",
       "      <td>-0.001677</td>\n",
       "      <td>-0.005588</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>10</td>\n",
       "      <td>0.820707</td>\n",
       "      <td>0.825112</td>\n",
       "      <td>0.823968</td>\n",
       "      <td>0.823263</td>\n",
       "      <td>0.001866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.197876</td>\n",
       "      <td>0.028126</td>\n",
       "      <td>0.066315</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 1, 'gamma': 100}</td>\n",
       "      <td>-0.005696</td>\n",
       "      <td>-0.011553</td>\n",
       "      <td>-0.001930</td>\n",
       "      <td>-0.006393</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>14</td>\n",
       "      <td>0.820812</td>\n",
       "      <td>0.825150</td>\n",
       "      <td>0.823991</td>\n",
       "      <td>0.823318</td>\n",
       "      <td>0.001834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.255404</td>\n",
       "      <td>0.018097</td>\n",
       "      <td>0.017025</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1}</td>\n",
       "      <td>0.611408</td>\n",
       "      <td>0.597553</td>\n",
       "      <td>0.641277</td>\n",
       "      <td>0.616746</td>\n",
       "      <td>0.018245</td>\n",
       "      <td>3</td>\n",
       "      <td>0.854408</td>\n",
       "      <td>0.864775</td>\n",
       "      <td>0.859809</td>\n",
       "      <td>0.859664</td>\n",
       "      <td>0.004234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.106985</td>\n",
       "      <td>0.005939</td>\n",
       "      <td>0.025566</td>\n",
       "      <td>0.006514</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 10, 'gamma': 1}</td>\n",
       "      <td>0.125634</td>\n",
       "      <td>0.118724</td>\n",
       "      <td>0.127941</td>\n",
       "      <td>0.124100</td>\n",
       "      <td>0.003916</td>\n",
       "      <td>5</td>\n",
       "      <td>0.825999</td>\n",
       "      <td>0.829066</td>\n",
       "      <td>0.830193</td>\n",
       "      <td>0.828420</td>\n",
       "      <td>0.001772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.131109</td>\n",
       "      <td>0.011194</td>\n",
       "      <td>0.025420</td>\n",
       "      <td>0.004343</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 10, 'gamma': 10}</td>\n",
       "      <td>-0.004696</td>\n",
       "      <td>-0.010390</td>\n",
       "      <td>-0.001677</td>\n",
       "      <td>-0.005588</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>10</td>\n",
       "      <td>0.820707</td>\n",
       "      <td>0.825112</td>\n",
       "      <td>0.823968</td>\n",
       "      <td>0.823263</td>\n",
       "      <td>0.001866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.178828</td>\n",
       "      <td>0.016511</td>\n",
       "      <td>0.056789</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 10, 'gamma': 100}</td>\n",
       "      <td>-0.005696</td>\n",
       "      <td>-0.011553</td>\n",
       "      <td>-0.001930</td>\n",
       "      <td>-0.006393</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>14</td>\n",
       "      <td>0.820812</td>\n",
       "      <td>0.825150</td>\n",
       "      <td>0.823991</td>\n",
       "      <td>0.823318</td>\n",
       "      <td>0.001834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.212806</td>\n",
       "      <td>0.011244</td>\n",
       "      <td>0.015520</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 100, 'gamma': 0.1}</td>\n",
       "      <td>0.598564</td>\n",
       "      <td>0.583609</td>\n",
       "      <td>0.625706</td>\n",
       "      <td>0.602626</td>\n",
       "      <td>0.017425</td>\n",
       "      <td>4</td>\n",
       "      <td>0.857395</td>\n",
       "      <td>0.866296</td>\n",
       "      <td>0.860651</td>\n",
       "      <td>0.861448</td>\n",
       "      <td>0.003677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.096109</td>\n",
       "      <td>0.004042</td>\n",
       "      <td>0.024308</td>\n",
       "      <td>0.005466</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 100, 'gamma': 1}</td>\n",
       "      <td>0.125634</td>\n",
       "      <td>0.118724</td>\n",
       "      <td>0.127941</td>\n",
       "      <td>0.124100</td>\n",
       "      <td>0.003916</td>\n",
       "      <td>5</td>\n",
       "      <td>0.825999</td>\n",
       "      <td>0.829066</td>\n",
       "      <td>0.830193</td>\n",
       "      <td>0.828420</td>\n",
       "      <td>0.001772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.137239</td>\n",
       "      <td>0.004541</td>\n",
       "      <td>0.023845</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 100, 'gamma': 10}</td>\n",
       "      <td>-0.004696</td>\n",
       "      <td>-0.010390</td>\n",
       "      <td>-0.001677</td>\n",
       "      <td>-0.005588</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>10</td>\n",
       "      <td>0.820707</td>\n",
       "      <td>0.825112</td>\n",
       "      <td>0.823968</td>\n",
       "      <td>0.823263</td>\n",
       "      <td>0.001866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.121457</td>\n",
       "      <td>0.010148</td>\n",
       "      <td>0.033644</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 100, 'gamma': 100}</td>\n",
       "      <td>-0.005696</td>\n",
       "      <td>-0.011553</td>\n",
       "      <td>-0.001930</td>\n",
       "      <td>-0.006393</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>14</td>\n",
       "      <td>0.820812</td>\n",
       "      <td>0.825150</td>\n",
       "      <td>0.823991</td>\n",
       "      <td>0.823318</td>\n",
       "      <td>0.001834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.058465      0.002525         0.014301        0.002612     0.1   \n",
       "1        0.092396      0.013784         0.030649        0.005806     0.1   \n",
       "2        0.112345      0.012555         0.022735        0.001225     0.1   \n",
       "3        0.159410      0.010241         0.050031        0.003737     0.1   \n",
       "4        0.118071      0.008566         0.014900        0.000826       1   \n",
       "5        0.108773      0.017845         0.027454        0.006283       1   \n",
       "6        0.112883      0.010936         0.026524        0.001792       1   \n",
       "7        0.197876      0.028126         0.066315        0.006267       1   \n",
       "8        0.255404      0.018097         0.017025        0.000821      10   \n",
       "9        0.106985      0.005939         0.025566        0.006514      10   \n",
       "10       0.131109      0.011194         0.025420        0.004343      10   \n",
       "11       0.178828      0.016511         0.056789        0.001567      10   \n",
       "12       0.212806      0.011244         0.015520        0.000712     100   \n",
       "13       0.096109      0.004042         0.024308        0.005466     100   \n",
       "14       0.137239      0.004541         0.023845        0.003803     100   \n",
       "15       0.121457      0.010148         0.033644        0.004540     100   \n",
       "\n",
       "   param_gamma                    params  split0_test_score  \\\n",
       "0          0.1  {'C': 0.1, 'gamma': 0.1}           0.643627   \n",
       "1            1    {'C': 0.1, 'gamma': 1}           0.077404   \n",
       "2           10   {'C': 0.1, 'gamma': 10}          -0.000727   \n",
       "3          100  {'C': 0.1, 'gamma': 100}          -0.001676   \n",
       "4          0.1    {'C': 1, 'gamma': 0.1}           0.658039   \n",
       "5            1      {'C': 1, 'gamma': 1}           0.125634   \n",
       "6           10     {'C': 1, 'gamma': 10}          -0.004696   \n",
       "7          100    {'C': 1, 'gamma': 100}          -0.005696   \n",
       "8          0.1   {'C': 10, 'gamma': 0.1}           0.611408   \n",
       "9            1     {'C': 10, 'gamma': 1}           0.125634   \n",
       "10          10    {'C': 10, 'gamma': 10}          -0.004696   \n",
       "11         100   {'C': 10, 'gamma': 100}          -0.005696   \n",
       "12         0.1  {'C': 100, 'gamma': 0.1}           0.598564   \n",
       "13           1    {'C': 100, 'gamma': 1}           0.125634   \n",
       "14          10   {'C': 100, 'gamma': 10}          -0.004696   \n",
       "15         100  {'C': 100, 'gamma': 100}          -0.005696   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.654478           0.647687         0.648597        0.004477   \n",
       "1            0.082293           0.067362         0.075686        0.006215   \n",
       "2           -0.000383          -0.015475        -0.005528        0.007035   \n",
       "3           -0.001624          -0.015465        -0.006255        0.006512   \n",
       "4            0.659721           0.673304         0.663688        0.006834   \n",
       "5            0.118724           0.127941         0.124100        0.003916   \n",
       "6           -0.010390          -0.001677        -0.005588        0.003612   \n",
       "7           -0.011553          -0.001930        -0.006393        0.003959   \n",
       "8            0.597553           0.641277         0.616746        0.018245   \n",
       "9            0.118724           0.127941         0.124100        0.003916   \n",
       "10          -0.010390          -0.001677        -0.005588        0.003612   \n",
       "11          -0.011553          -0.001930        -0.006393        0.003959   \n",
       "12           0.583609           0.625706         0.602626        0.017425   \n",
       "13           0.118724           0.127941         0.124100        0.003916   \n",
       "14          -0.010390          -0.001677        -0.005588        0.003612   \n",
       "15          -0.011553          -0.001930        -0.006393        0.003959   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                 2            0.747270            0.747831   \n",
       "1                 8            0.504675            0.493443   \n",
       "2                 9            0.473397            0.454660   \n",
       "3                13            0.473200            0.454666   \n",
       "4                 1            0.838128            0.846661   \n",
       "5                 5            0.825999            0.829066   \n",
       "6                10            0.820707            0.825112   \n",
       "7                14            0.820812            0.825150   \n",
       "8                 3            0.854408            0.864775   \n",
       "9                 5            0.825999            0.829066   \n",
       "10               10            0.820707            0.825112   \n",
       "11               14            0.820812            0.825150   \n",
       "12                4            0.857395            0.866296   \n",
       "13                5            0.825999            0.829066   \n",
       "14               10            0.820707            0.825112   \n",
       "15               14            0.820812            0.825150   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "0             0.743444          0.746182         0.001950  \n",
       "1             0.504388          0.500835         0.005228  \n",
       "2             0.467935          0.465331         0.007868  \n",
       "3             0.467520          0.465129         0.007753  \n",
       "4             0.844749          0.843179         0.003656  \n",
       "5             0.830193          0.828420         0.001772  \n",
       "6             0.823968          0.823263         0.001866  \n",
       "7             0.823991          0.823318         0.001834  \n",
       "8             0.859809          0.859664         0.004234  \n",
       "9             0.830193          0.828420         0.001772  \n",
       "10            0.823968          0.823263         0.001866  \n",
       "11            0.823991          0.823318         0.001834  \n",
       "12            0.860651          0.861448         0.003677  \n",
       "13            0.830193          0.828420         0.001772  \n",
       "14            0.823968          0.823263         0.001866  \n",
       "15            0.823991          0.823318         0.001834  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_rbf = pd.DataFrame(grid_svr_rbf.cv_results_)\n",
    "result_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee52008b00>]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee52008f28>]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x1ee51ff8198>,\n",
       "  <matplotlib.axis.XTick at 0x1ee51ff5b00>,\n",
       "  <matplotlib.axis.XTick at 0x1ee51ff5a20>,\n",
       "  <matplotlib.axis.XTick at 0x1ee5201c5f8>,\n",
       "  <matplotlib.axis.XTick at 0x1ee5201cb00>,\n",
       "  <matplotlib.axis.XTick at 0x1ee5201f160>],\n",
       " <a list of 6 Text xticklabel objects>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee52008e80>]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ee51ff5630>]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ee5201ff28>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(result_rbf.shape[0]), result_rbf['mean_train_score'], label = 'mean train score')\n",
    "plt.plot(range(result_rbf.shape[0]), result_rbf['mean_test_score'], label = 'mean test score')\n",
    "plt.xticks(range(result_svr_poly.shape[0]), result_rbf['param_C'], rotation = 90)\n",
    "plt.plot([grid_svr_rbf.best_index_], result_rbf['mean_train_score'][grid_svr_rbf.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.plot([grid_svr_rbf.best_index_], result_rbf['mean_test_score'][grid_svr_rbf.best_index_], 'o', markersize = 10, fillstyle = \"none\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR with Kernel 'rbf' Summary:\n",
    "\n",
    "#### Train Score: 0.8601\n",
    "\n",
    "#### Test Score: 0.5393\n",
    "\n",
    "#### Best Parameters: {'C': 1, 'gamma': 0.1}\n",
    "\n",
    "#### Best Cross - Validation Score: 0.6637"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Model': ['Linear Regression', 'KNN Regression','Ridge Regression','Lasso Regression',\n",
    "               'Polynominal Regression','Simple SVR','SVR with Linear kernel','SVR with Poly kernel',\n",
    "               'SVR with rbf kernel'], \n",
    "     'Cross-Validation Score':[0.711074, 0.550138, 0.709673, 0.601946, 0.709610, 0.706442, 0.711354, 0.737803,\n",
    "                              0.742461]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross-Validation Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.711074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Regression</td>\n",
       "      <td>0.550138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>0.709673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>0.601946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Polynominal Regression</td>\n",
       "      <td>0.709610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Simple SVR</td>\n",
       "      <td>0.706442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVR with Linear kernel</td>\n",
       "      <td>0.711354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVR with Poly kernel</td>\n",
       "      <td>0.737803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVR with rbf kernel</td>\n",
       "      <td>0.742461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Cross-Validation Score\n",
       "0       Linear Regression                0.711074\n",
       "1          KNN Regression                0.550138\n",
       "2        Ridge Regression                0.709673\n",
       "3        Lasso Regression                0.601946\n",
       "4  Polynominal Regression                0.709610\n",
       "5              Simple SVR                0.706442\n",
       "6  SVR with Linear kernel                0.711354\n",
       "7    SVR with Poly kernel                0.737803\n",
       "8     SVR with rbf kernel                0.742461"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(data=d)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note : The above results are from Project 1 - Regression Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {'Model': ['Linear Regression', 'KNN Regression','Ridge Regression','Lasso Regression',\n",
    "                    'Polynominal Regression','Simple SVR','SVR with Linear kernel','SVR with Poly kernel',\n",
    "                    'SVR with rbf kernel'],\n",
    "          'Cross-Validation Score': [grid_search_lr.best_score_, grid_search_knn.best_score_, \n",
    "                                     grid_search_ridge.best_score_, grid_search_lasso.best_score_, \n",
    "                                     grid_poly.best_score_, grid_svrl.best_score_, grid_svr_linear.best_score_,\n",
    "                                     grid_svr_poly.best_score_, grid_svr_rbf.best_score_]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Cross-Validation Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.689648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Regression</td>\n",
       "      <td>0.625835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>0.688463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>0.668594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Polynominal Regression</td>\n",
       "      <td>0.707032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Simple SVR</td>\n",
       "      <td>0.686692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVR with Linear kernel</td>\n",
       "      <td>0.689862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVR with Poly kernel</td>\n",
       "      <td>0.689142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVR with rbf kernel</td>\n",
       "      <td>0.663688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Cross-Validation Score\n",
       "0       Linear Regression                0.689648\n",
       "1          KNN Regression                0.625835\n",
       "2        Ridge Regression                0.688463\n",
       "3        Lasso Regression                0.668594\n",
       "4  Polynominal Regression                0.707032\n",
       "5              Simple SVR                0.686692\n",
       "6  SVR with Linear kernel                0.689862\n",
       "7    SVR with Poly kernel                0.689142\n",
       "8     SVR with rbf kernel                0.663688"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(data=result)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We obtained better results with PCA for KNN Regression and Lasso Regression. Overall, it turns out to be almost same and not much of a difference after applying PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (1.14.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from tensorflow) (0.9.0)\n",
      "Collecting google-pasta>=0.1.6\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from tensorflow) (0.33.4)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.4)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from tensorflow) (0.8.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (41.0.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (0.15.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow) (2.9.0)\n",
      "Installing collected packages: google-pasta\n",
      "Successfully installed google-pasta-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\dhurv\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from keras) (1.16.4)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from keras) (1.2.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from keras) (5.1.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: keras_applications>=1.0.6 in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: keras_preprocessing>=1.0.5 in c:\\users\\dhurv\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\dhurv\\Anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nn = np.asarray(X_train_scale)\n",
    "X_test_nn = np.asarray(X_test_scale)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1512, 14)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_nn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dhurv\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Epoch 1/1000\n",
      "1512/1512 [==============================] - 1s 449us/sample - loss: 0.0837\n",
      "Epoch 2/1000\n",
      "1512/1512 [==============================] - 0s 15us/sample - loss: 0.0692\n",
      "Epoch 3/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0587\n",
      "Epoch 4/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0514\n",
      "Epoch 5/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0469\n",
      "Epoch 6/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0435\n",
      "Epoch 7/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0407\n",
      "Epoch 8/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0382\n",
      "Epoch 9/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0359\n",
      "Epoch 10/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0338\n",
      "Epoch 11/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0320\n",
      "Epoch 12/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0303\n",
      "Epoch 13/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0287\n",
      "Epoch 14/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0271\n",
      "Epoch 15/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0258\n",
      "Epoch 16/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0246\n",
      "Epoch 17/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0235\n",
      "Epoch 18/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0224\n",
      "Epoch 19/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0215\n",
      "Epoch 20/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0206\n",
      "Epoch 21/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0198\n",
      "Epoch 22/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0191\n",
      "Epoch 23/1000\n",
      "1512/1512 [==============================] - 0s 16us/sample - loss: 0.0184\n",
      "Epoch 24/1000\n",
      "1512/1512 [==============================] - 0s 10us/sample - loss: 0.0179\n",
      "Epoch 25/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0173\n",
      "Epoch 26/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0168\n",
      "Epoch 27/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0163\n",
      "Epoch 28/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0159\n",
      "Epoch 29/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0155\n",
      "Epoch 30/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0152\n",
      "Epoch 31/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0149\n",
      "Epoch 32/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0146\n",
      "Epoch 33/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0143\n",
      "Epoch 34/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0141\n",
      "Epoch 35/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0139\n",
      "Epoch 36/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0137\n",
      "Epoch 37/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0135\n",
      "Epoch 38/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0133\n",
      "Epoch 39/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0131\n",
      "Epoch 40/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0130\n",
      "Epoch 41/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0128\n",
      "Epoch 42/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0127\n",
      "Epoch 43/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0126\n",
      "Epoch 44/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0125\n",
      "Epoch 45/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0124\n",
      "Epoch 46/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0123\n",
      "Epoch 47/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0122\n",
      "Epoch 48/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0121\n",
      "Epoch 49/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0120\n",
      "Epoch 50/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0120\n",
      "Epoch 51/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0119\n",
      "Epoch 52/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0118\n",
      "Epoch 53/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0118\n",
      "Epoch 54/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0117\n",
      "Epoch 55/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0116\n",
      "Epoch 56/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0116\n",
      "Epoch 57/1000\n",
      "1512/1512 [==============================] - 0s 10us/sample - loss: 0.0115\n",
      "Epoch 58/1000\n",
      "1512/1512 [==============================] - 0s 17us/sample - loss: 0.0115\n",
      "Epoch 59/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0114\n",
      "Epoch 60/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0114\n",
      "Epoch 61/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0113\n",
      "Epoch 62/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0113\n",
      "Epoch 63/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0113\n",
      "Epoch 64/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0112\n",
      "Epoch 65/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0112\n",
      "Epoch 66/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0111\n",
      "Epoch 67/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0111\n",
      "Epoch 68/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0110\n",
      "Epoch 69/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0110\n",
      "Epoch 70/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0110\n",
      "Epoch 71/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0109\n",
      "Epoch 72/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0109\n",
      "Epoch 73/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0108\n",
      "Epoch 74/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0108\n",
      "Epoch 75/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0108\n",
      "Epoch 76/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0108\n",
      "Epoch 77/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0107\n",
      "Epoch 78/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0107\n",
      "Epoch 79/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0107\n",
      "Epoch 80/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0107\n",
      "Epoch 81/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0106\n",
      "Epoch 82/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0106\n",
      "Epoch 83/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0106\n",
      "Epoch 84/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0106\n",
      "Epoch 85/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0106\n",
      "Epoch 86/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0105\n",
      "Epoch 87/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0105\n",
      "Epoch 88/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0105\n",
      "Epoch 89/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 0s 12us/sample - loss: 0.0105\n",
      "Epoch 90/1000\n",
      "1512/1512 [==============================] - 0s 13us/sample - loss: 0.0105\n",
      "Epoch 91/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0105\n",
      "Epoch 92/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0104\n",
      "Epoch 93/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0104\n",
      "Epoch 94/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0104\n",
      "Epoch 95/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0104\n",
      "Epoch 96/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0104\n",
      "Epoch 97/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0104\n",
      "Epoch 98/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0104\n",
      "Epoch 99/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0103\n",
      "Epoch 100/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0103\n",
      "Epoch 101/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0103\n",
      "Epoch 102/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0103\n",
      "Epoch 103/1000\n",
      "1512/1512 [==============================] - 0s 17us/sample - loss: 0.0103\n",
      "Epoch 104/1000\n",
      "1512/1512 [==============================] - 0s 14us/sample - loss: 0.0103\n",
      "Epoch 105/1000\n",
      "1512/1512 [==============================] - 0s 13us/sample - loss: 0.0103\n",
      "Epoch 106/1000\n",
      "1512/1512 [==============================] - 0s 16us/sample - loss: 0.0103\n",
      "Epoch 107/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0102\n",
      "Epoch 108/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0102\n",
      "Epoch 109/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0102\n",
      "Epoch 110/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0102\n",
      "Epoch 111/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0102\n",
      "Epoch 112/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0102\n",
      "Epoch 113/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0102\n",
      "Epoch 114/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0101\n",
      "Epoch 115/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0102\n",
      "Epoch 116/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0102\n",
      "Epoch 117/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0101\n",
      "Epoch 118/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0101\n",
      "Epoch 119/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0101\n",
      "Epoch 120/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0101\n",
      "Epoch 121/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0101\n",
      "Epoch 122/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0101\n",
      "Epoch 123/1000\n",
      "1512/1512 [==============================] - 0s 11us/sample - loss: 0.0101\n",
      "Epoch 124/1000\n",
      "1512/1512 [==============================] - 0s 14us/sample - loss: 0.0101\n",
      "Epoch 125/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0101\n",
      "Epoch 126/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0100\n",
      "Epoch 127/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0100\n",
      "Epoch 128/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0100\n",
      "Epoch 129/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0101\n",
      "Epoch 130/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0100\n",
      "Epoch 131/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0100\n",
      "Epoch 132/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0100\n",
      "Epoch 133/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0100\n",
      "Epoch 134/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0100\n",
      "Epoch 135/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0099\n",
      "Epoch 136/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0099\n",
      "Epoch 137/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0099\n",
      "Epoch 138/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0099\n",
      "Epoch 139/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0099\n",
      "Epoch 140/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0099\n",
      "Epoch 141/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0099\n",
      "Epoch 142/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0099\n",
      "Epoch 143/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0099\n",
      "Epoch 144/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0099\n",
      "Epoch 145/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0098\n",
      "Epoch 146/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0098\n",
      "Epoch 147/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0098\n",
      "Epoch 148/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0098\n",
      "Epoch 149/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0098\n",
      "Epoch 150/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0098\n",
      "Epoch 151/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0098\n",
      "Epoch 152/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0098\n",
      "Epoch 153/1000\n",
      "1512/1512 [==============================] - 0s 27us/sample - loss: 0.0098\n",
      "Epoch 154/1000\n",
      "1512/1512 [==============================] - 0s 16us/sample - loss: 0.0098\n",
      "Epoch 155/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0097\n",
      "Epoch 156/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0097\n",
      "Epoch 157/1000\n",
      "1512/1512 [==============================] - 0s 17us/sample - loss: 0.0097\n",
      "Epoch 158/1000\n",
      "1512/1512 [==============================] - 0s 17us/sample - loss: 0.0097\n",
      "Epoch 159/1000\n",
      "1512/1512 [==============================] - 0s 15us/sample - loss: 0.0097\n",
      "Epoch 160/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0097\n",
      "Epoch 161/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0097\n",
      "Epoch 162/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0097\n",
      "Epoch 163/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0097\n",
      "Epoch 164/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0097\n",
      "Epoch 165/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0097\n",
      "Epoch 166/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0096\n",
      "Epoch 167/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0096\n",
      "Epoch 168/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0096\n",
      "Epoch 169/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0096\n",
      "Epoch 170/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0096\n",
      "Epoch 171/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0096\n",
      "Epoch 172/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0096\n",
      "Epoch 173/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0096\n",
      "Epoch 174/1000\n",
      "1512/1512 [==============================] - 0s 25us/sample - loss: 0.0096\n",
      "Epoch 175/1000\n",
      "1512/1512 [==============================] - 0s 32us/sample - loss: 0.0095\n",
      "Epoch 176/1000\n",
      "1512/1512 [==============================] - 0s 15us/sample - loss: 0.0096\n",
      "Epoch 177/1000\n",
      "1512/1512 [==============================] - 0s 10us/sample - loss: 0.0095\n",
      "Epoch 178/1000\n",
      "1512/1512 [==============================] - 0s 11us/sample - loss: 0.0095\n",
      "Epoch 179/1000\n",
      "1512/1512 [==============================] - 0s 13us/sample - loss: 0.0095\n",
      "Epoch 180/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0095\n",
      "Epoch 181/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0095\n",
      "Epoch 182/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0095\n",
      "Epoch 183/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0095\n",
      "Epoch 184/1000\n",
      "1512/1512 [==============================] - 0s 17us/sample - loss: 0.0095\n",
      "Epoch 185/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0095\n",
      "Epoch 186/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0095\n",
      "Epoch 187/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0095\n",
      "Epoch 188/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0095\n",
      "Epoch 189/1000\n",
      "1512/1512 [==============================] - 0s 17us/sample - loss: 0.0095\n",
      "Epoch 190/1000\n",
      "1512/1512 [==============================] - 0s 17us/sample - loss: 0.0094\n",
      "Epoch 191/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0094\n",
      "Epoch 192/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0094\n",
      "Epoch 193/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0094\n",
      "Epoch 194/1000\n",
      "1512/1512 [==============================] - 0s 29us/sample - loss: 0.0094\n",
      "Epoch 195/1000\n",
      "1512/1512 [==============================] - 0s 25us/sample - loss: 0.0094\n",
      "Epoch 196/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0094\n",
      "Epoch 197/1000\n",
      "1512/1512 [==============================] - 0s 25us/sample - loss: 0.0094\n",
      "Epoch 198/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0094\n",
      "Epoch 199/1000\n",
      "1512/1512 [==============================] - 0s 25us/sample - loss: 0.0094\n",
      "Epoch 200/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0094\n",
      "Epoch 201/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0094\n",
      "Epoch 202/1000\n",
      "1512/1512 [==============================] - 0s 26us/sample - loss: 0.0094\n",
      "Epoch 203/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0093\n",
      "Epoch 204/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0093\n",
      "Epoch 205/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0093\n",
      "Epoch 206/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0093\n",
      "Epoch 207/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0093\n",
      "Epoch 208/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0093\n",
      "Epoch 209/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0093\n",
      "Epoch 210/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0094\n",
      "Epoch 211/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0093\n",
      "Epoch 212/1000\n",
      "1512/1512 [==============================] - 0s 26us/sample - loss: 0.0093\n",
      "Epoch 213/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0093\n",
      "Epoch 214/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0093\n",
      "Epoch 215/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0093\n",
      "Epoch 216/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0093\n",
      "Epoch 217/1000\n",
      "1512/1512 [==============================] - 0s 25us/sample - loss: 0.0093\n",
      "Epoch 218/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0093\n",
      "Epoch 219/1000\n",
      "1512/1512 [==============================] - 0s 16us/sample - loss: 0.0093\n",
      "Epoch 220/1000\n",
      "1512/1512 [==============================] - 0s 15us/sample - loss: 0.0092\n",
      "Epoch 221/1000\n",
      "1512/1512 [==============================] - 0s 11us/sample - loss: 0.0093\n",
      "Epoch 222/1000\n",
      "1512/1512 [==============================] - 0s 15us/sample - loss: 0.0093\n",
      "Epoch 223/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0092\n",
      "Epoch 224/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0093\n",
      "Epoch 225/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0092\n",
      "Epoch 226/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0092\n",
      "Epoch 227/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0092\n",
      "Epoch 228/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0092\n",
      "Epoch 229/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0092\n",
      "Epoch 230/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0092\n",
      "Epoch 231/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0092\n",
      "Epoch 232/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0092\n",
      "Epoch 233/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0092\n",
      "Epoch 234/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0092\n",
      "Epoch 235/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0092\n",
      "Epoch 236/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0092\n",
      "Epoch 237/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0092\n",
      "Epoch 238/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0092\n",
      "Epoch 239/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0092\n",
      "Epoch 240/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0092\n",
      "Epoch 241/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0092\n",
      "Epoch 242/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0091\n",
      "Epoch 243/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0091\n",
      "Epoch 244/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0092\n",
      "Epoch 245/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0091\n",
      "Epoch 246/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0091\n",
      "Epoch 247/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0091\n",
      "Epoch 248/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0091\n",
      "Epoch 249/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0091\n",
      "Epoch 250/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0091\n",
      "Epoch 251/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0091\n",
      "Epoch 252/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0091\n",
      "Epoch 253/1000\n",
      "1512/1512 [==============================] - 0s 11us/sample - loss: 0.0091\n",
      "Epoch 254/1000\n",
      "1512/1512 [==============================] - 0s 13us/sample - loss: 0.0091\n",
      "Epoch 255/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0091\n",
      "Epoch 256/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0091\n",
      "Epoch 257/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0091\n",
      "Epoch 258/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0090\n",
      "Epoch 259/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0091\n",
      "Epoch 260/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0090\n",
      "Epoch 261/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0090\n",
      "Epoch 262/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0090\n",
      "Epoch 263/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0090\n",
      "Epoch 264/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0090\n",
      "Epoch 265/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0090\n",
      "Epoch 266/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0090\n",
      "Epoch 267/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0090\n",
      "Epoch 268/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0090\n",
      "Epoch 269/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0090\n",
      "Epoch 270/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0090\n",
      "Epoch 271/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0090\n",
      "Epoch 272/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0090\n",
      "Epoch 273/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0090\n",
      "Epoch 274/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0090\n",
      "Epoch 275/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0090\n",
      "Epoch 276/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0090\n",
      "Epoch 277/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0090\n",
      "Epoch 278/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0089\n",
      "Epoch 279/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0089\n",
      "Epoch 280/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0089\n",
      "Epoch 281/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0089\n",
      "Epoch 282/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0089\n",
      "Epoch 283/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0090\n",
      "Epoch 284/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0090\n",
      "Epoch 285/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0089\n",
      "Epoch 286/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0089\n",
      "Epoch 287/1000\n",
      "1512/1512 [==============================] - 0s 11us/sample - loss: 0.0089\n",
      "Epoch 288/1000\n",
      "1512/1512 [==============================] - 0s 12us/sample - loss: 0.0089\n",
      "Epoch 289/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0089\n",
      "Epoch 290/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0089\n",
      "Epoch 291/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0089\n",
      "Epoch 292/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0089\n",
      "Epoch 293/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0089\n",
      "Epoch 294/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0089\n",
      "Epoch 295/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0089\n",
      "Epoch 296/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0089\n",
      "Epoch 297/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0089\n",
      "Epoch 298/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0089\n",
      "Epoch 299/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0088\n",
      "Epoch 300/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0088\n",
      "Epoch 301/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0089\n",
      "Epoch 302/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0088\n",
      "Epoch 303/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0089\n",
      "Epoch 304/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0088\n",
      "Epoch 305/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0088\n",
      "Epoch 306/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0088\n",
      "Epoch 307/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0088\n",
      "Epoch 308/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0088\n",
      "Epoch 309/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0088\n",
      "Epoch 310/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0088\n",
      "Epoch 311/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0088\n",
      "Epoch 312/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0088\n",
      "Epoch 313/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0088\n",
      "Epoch 314/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0088\n",
      "Epoch 315/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0088\n",
      "Epoch 316/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0088\n",
      "Epoch 317/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0088\n",
      "Epoch 318/1000\n",
      "1512/1512 [==============================] - 0s 25us/sample - loss: 0.0088\n",
      "Epoch 319/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0088\n",
      "Epoch 320/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0088\n",
      "Epoch 321/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0087\n",
      "Epoch 322/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0087\n",
      "Epoch 323/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0088\n",
      "Epoch 324/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0087\n",
      "Epoch 325/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0088\n",
      "Epoch 326/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0087\n",
      "Epoch 327/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0088\n",
      "Epoch 328/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0087\n",
      "Epoch 329/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0087\n",
      "Epoch 330/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0087\n",
      "Epoch 331/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0087\n",
      "Epoch 332/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0087\n",
      "Epoch 333/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0087\n",
      "Epoch 334/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0087\n",
      "Epoch 335/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0087\n",
      "Epoch 336/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0087\n",
      "Epoch 337/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0087\n",
      "Epoch 338/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0087\n",
      "Epoch 339/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0087\n",
      "Epoch 340/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0087\n",
      "Epoch 341/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0087\n",
      "Epoch 342/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0087\n",
      "Epoch 343/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0087\n",
      "Epoch 344/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0087\n",
      "Epoch 345/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0087\n",
      "Epoch 346/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0087\n",
      "Epoch 347/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0087\n",
      "Epoch 348/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0087\n",
      "Epoch 349/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0086\n",
      "Epoch 350/1000\n",
      "1512/1512 [==============================] - 0s 26us/sample - loss: 0.0087\n",
      "Epoch 351/1000\n",
      "1512/1512 [==============================] - 0s 25us/sample - loss: 0.0086\n",
      "Epoch 352/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0086\n",
      "Epoch 353/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0086\n",
      "Epoch 354/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0086\n",
      "Epoch 355/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0086\n",
      "Epoch 356/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0086\n",
      "Epoch 357/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0086\n",
      "Epoch 358/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0086\n",
      "Epoch 359/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0086\n",
      "Epoch 360/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0086\n",
      "Epoch 361/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0086\n",
      "Epoch 362/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0086\n",
      "Epoch 363/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0086\n",
      "Epoch 364/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0086\n",
      "Epoch 365/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0086\n",
      "Epoch 366/1000\n",
      "1512/1512 [==============================] - 0s 25us/sample - loss: 0.0086\n",
      "Epoch 367/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0086\n",
      "Epoch 368/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0086\n",
      "Epoch 369/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0086\n",
      "Epoch 370/1000\n",
      "1512/1512 [==============================] - 0s 14us/sample - loss: 0.0086\n",
      "Epoch 371/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0086\n",
      "Epoch 372/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0086\n",
      "Epoch 373/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0086\n",
      "Epoch 374/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0086\n",
      "Epoch 375/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0086\n",
      "Epoch 376/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0085\n",
      "Epoch 377/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0086\n",
      "Epoch 378/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0086\n",
      "Epoch 379/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0086\n",
      "Epoch 380/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0085\n",
      "Epoch 381/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0085\n",
      "Epoch 382/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0085\n",
      "Epoch 383/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0085\n",
      "Epoch 384/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0085\n",
      "Epoch 385/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0085\n",
      "Epoch 386/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0085\n",
      "Epoch 387/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0085\n",
      "Epoch 388/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0085\n",
      "Epoch 389/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0085\n",
      "Epoch 390/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0085\n",
      "Epoch 391/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0085\n",
      "Epoch 392/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0085\n",
      "Epoch 393/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0085\n",
      "Epoch 394/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0085\n",
      "Epoch 395/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0085\n",
      "Epoch 396/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0085\n",
      "Epoch 397/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0085\n",
      "Epoch 398/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0085\n",
      "Epoch 399/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0085\n",
      "Epoch 400/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0085\n",
      "Epoch 401/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0085\n",
      "Epoch 402/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0085\n",
      "Epoch 403/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0085\n",
      "Epoch 404/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0085\n",
      "Epoch 405/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0085\n",
      "Epoch 406/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0085\n",
      "Epoch 407/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0085\n",
      "Epoch 408/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0085\n",
      "Epoch 409/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0085\n",
      "Epoch 410/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0085\n",
      "Epoch 411/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0085\n",
      "Epoch 412/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0085\n",
      "Epoch 413/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0085\n",
      "Epoch 414/1000\n",
      "1512/1512 [==============================] - 0s 35us/sample - loss: 0.0084\n",
      "Epoch 415/1000\n",
      "1512/1512 [==============================] - 0s 16us/sample - loss: 0.0084\n",
      "Epoch 416/1000\n",
      "1512/1512 [==============================] - 0s 14us/sample - loss: 0.0085\n",
      "Epoch 417/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0084\n",
      "Epoch 418/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0084\n",
      "Epoch 419/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0085\n",
      "Epoch 420/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0085\n",
      "Epoch 421/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0084\n",
      "Epoch 422/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0084\n",
      "Epoch 423/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0084\n",
      "Epoch 424/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0084\n",
      "Epoch 425/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0084\n",
      "Epoch 426/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0084\n",
      "Epoch 427/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0084\n",
      "Epoch 428/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0084\n",
      "Epoch 429/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0084\n",
      "Epoch 430/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0084\n",
      "Epoch 431/1000\n",
      "1512/1512 [==============================] - 0s 15us/sample - loss: 0.0084\n",
      "Epoch 432/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0084\n",
      "Epoch 433/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0084\n",
      "Epoch 434/1000\n",
      "1512/1512 [==============================] - 0s 40us/sample - loss: 0.0084\n",
      "Epoch 435/1000\n",
      "1512/1512 [==============================] - 0s 13us/sample - loss: 0.0085\n",
      "Epoch 436/1000\n",
      "1512/1512 [==============================] - 0s 11us/sample - loss: 0.0084\n",
      "Epoch 437/1000\n",
      "1512/1512 [==============================] - 0s 7us/sample - loss: 0.0084\n",
      "Epoch 438/1000\n",
      "1512/1512 [==============================] - 0s 9us/sample - loss: 0.0084\n",
      "Epoch 439/1000\n",
      "1512/1512 [==============================] - 0s 8us/sample - loss: 0.0084\n",
      "Epoch 440/1000\n",
      "1512/1512 [==============================] - 0s 9us/sample - loss: 0.0084\n",
      "Epoch 441/1000\n",
      "1512/1512 [==============================] - 0s 9us/sample - loss: 0.0084\n",
      "Epoch 442/1000\n",
      "1512/1512 [==============================] - 0s 9us/sample - loss: 0.0084\n",
      "Epoch 443/1000\n",
      "1512/1512 [==============================] - 0s 10us/sample - loss: 0.0084\n",
      "Epoch 444/1000\n",
      "1512/1512 [==============================] - 0s 9us/sample - loss: 0.0084\n",
      "Epoch 445/1000\n",
      "1512/1512 [==============================] - 0s 9us/sample - loss: 0.0084\n",
      "Epoch 446/1000\n",
      "1512/1512 [==============================] - 0s 10us/sample - loss: 0.0084\n",
      "Epoch 447/1000\n",
      "1512/1512 [==============================] - 0s 11us/sample - loss: 0.0084\n",
      "Epoch 448/1000\n",
      "1512/1512 [==============================] - 0s 11us/sample - loss: 0.0084\n",
      "Epoch 449/1000\n",
      "1512/1512 [==============================] - 0s 16us/sample - loss: 0.0084\n",
      "Epoch 450/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0084\n",
      "Epoch 451/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0084\n",
      "Epoch 452/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0084\n",
      "Epoch 453/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0084\n",
      "Epoch 454/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0084\n",
      "Epoch 455/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0084\n",
      "Epoch 456/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0084\n",
      "Epoch 457/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0084\n",
      "Epoch 458/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0084\n",
      "Epoch 459/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0084\n",
      "Epoch 460/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0084\n",
      "Epoch 461/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0084\n",
      "Epoch 462/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0084\n",
      "Epoch 463/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0084\n",
      "Epoch 464/1000\n",
      "1512/1512 [==============================] - 0s 25us/sample - loss: 0.0083\n",
      "Epoch 465/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0084\n",
      "Epoch 466/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0083\n",
      "Epoch 467/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0083\n",
      "Epoch 468/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0083\n",
      "Epoch 469/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0084\n",
      "Epoch 470/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0083\n",
      "Epoch 471/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0084\n",
      "Epoch 472/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0083\n",
      "Epoch 473/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0084\n",
      "Epoch 474/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0084\n",
      "Epoch 475/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0084\n",
      "Epoch 476/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0084\n",
      "Epoch 477/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0083\n",
      "Epoch 478/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0083\n",
      "Epoch 479/1000\n",
      "1512/1512 [==============================] - 0s 17us/sample - loss: 0.0083\n",
      "Epoch 480/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0083\n",
      "Epoch 481/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0083\n",
      "Epoch 482/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0083\n",
      "Epoch 483/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0083\n",
      "Epoch 484/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0083\n",
      "Epoch 485/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0083\n",
      "Epoch 486/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0083\n",
      "Epoch 487/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0083\n",
      "Epoch 488/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0083\n",
      "Epoch 489/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0083\n",
      "Epoch 490/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0083\n",
      "Epoch 491/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0083\n",
      "Epoch 492/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0083\n",
      "Epoch 493/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0084\n",
      "Epoch 494/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0083\n",
      "Epoch 495/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0083\n",
      "Epoch 496/1000\n",
      "1512/1512 [==============================] - 0s 16us/sample - loss: 0.0083\n",
      "Epoch 497/1000\n",
      "1512/1512 [==============================] - 0s 14us/sample - loss: 0.0083\n",
      "Epoch 498/1000\n",
      "1512/1512 [==============================] - 0s 13us/sample - loss: 0.0083\n",
      "Epoch 499/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0083\n",
      "Epoch 500/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0083\n",
      "Epoch 501/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0083\n",
      "Epoch 502/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0083\n",
      "Epoch 503/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0083\n",
      "Epoch 504/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0083\n",
      "Epoch 505/1000\n",
      "1512/1512 [==============================] - 0s 17us/sample - loss: 0.0083\n",
      "Epoch 506/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0083\n",
      "Epoch 507/1000\n",
      "1512/1512 [==============================] - 0s 16us/sample - loss: 0.0083\n",
      "Epoch 508/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0083\n",
      "Epoch 509/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0083\n",
      "Epoch 510/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0083\n",
      "Epoch 511/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0083\n",
      "Epoch 512/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0083\n",
      "Epoch 513/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0083\n",
      "Epoch 514/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0083\n",
      "Epoch 515/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0083\n",
      "Epoch 516/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0083\n",
      "Epoch 517/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0083\n",
      "Epoch 518/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0083\n",
      "Epoch 519/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0083\n",
      "Epoch 520/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0083\n",
      "Epoch 521/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0083\n",
      "Epoch 522/1000\n",
      "1512/1512 [==============================] - 0s 13us/sample - loss: 0.0083\n",
      "Epoch 523/1000\n",
      "1512/1512 [==============================] - 0s 16us/sample - loss: 0.0083\n",
      "Epoch 524/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0083\n",
      "Epoch 525/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0083\n",
      "Epoch 526/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0083\n",
      "Epoch 527/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0083\n",
      "Epoch 528/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0083\n",
      "Epoch 529/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0083\n",
      "Epoch 530/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0083\n",
      "Epoch 531/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0083\n",
      "Epoch 532/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0083\n",
      "Epoch 533/1000\n",
      "1512/1512 [==============================] - 0s 17us/sample - loss: 0.0083\n",
      "Epoch 534/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0083\n",
      "Epoch 535/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0083\n",
      "Epoch 536/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0083\n",
      "Epoch 537/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0083\n",
      "Epoch 538/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 539/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 540/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 541/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0083\n",
      "Epoch 542/1000\n",
      "1512/1512 [==============================] - 0s 16us/sample - loss: 0.0083\n",
      "Epoch 543/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0083\n",
      "Epoch 544/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0083\n",
      "Epoch 545/1000\n",
      "1512/1512 [==============================] - 0s 16us/sample - loss: 0.0082\n",
      "Epoch 546/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 547/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0083\n",
      "Epoch 548/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0083\n",
      "Epoch 549/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0083\n",
      "Epoch 550/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0083\n",
      "Epoch 551/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 552/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 553/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 554/1000\n",
      "1512/1512 [==============================] - 0s 17us/sample - loss: 0.0082\n",
      "Epoch 555/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 556/1000\n",
      "1512/1512 [==============================] - 0s 12us/sample - loss: 0.0082\n",
      "Epoch 557/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0082\n",
      "Epoch 558/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 559/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 560/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 561/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 562/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 563/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 564/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 565/1000\n",
      "1512/1512 [==============================] - ETA: 0s - loss: 0.009 - 0s 22us/sample - loss: 0.0082\n",
      "Epoch 566/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0082\n",
      "Epoch 567/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 568/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 569/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0083\n",
      "Epoch 570/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0082\n",
      "Epoch 571/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0082\n",
      "Epoch 572/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0082\n",
      "Epoch 573/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 574/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 575/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 576/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0082\n",
      "Epoch 577/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0082\n",
      "Epoch 578/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 579/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 580/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 581/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 582/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0082\n",
      "Epoch 583/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 584/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0082\n",
      "Epoch 585/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 586/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 587/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0082\n",
      "Epoch 588/1000\n",
      "1512/1512 [==============================] - 0s 16us/sample - loss: 0.0082\n",
      "Epoch 589/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0082\n",
      "Epoch 590/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 591/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 592/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 593/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 594/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 595/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 596/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 597/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0082\n",
      "Epoch 598/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 599/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 600/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 601/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 602/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 603/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 604/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 605/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 606/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0082\n",
      "Epoch 607/1000\n",
      "1512/1512 [==============================] - 0s 15us/sample - loss: 0.0082\n",
      "Epoch 608/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0082\n",
      "Epoch 609/1000\n",
      "1512/1512 [==============================] - 0s 26us/sample - loss: 0.0082\n",
      "Epoch 610/1000\n",
      "1512/1512 [==============================] - 0s 25us/sample - loss: 0.0081\n",
      "Epoch 611/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 612/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 613/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 614/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 615/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 616/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 617/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0082\n",
      "Epoch 618/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 619/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0082\n",
      "Epoch 620/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0081\n",
      "Epoch 621/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 622/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 623/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 624/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 625/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 626/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 627/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 628/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 629/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 630/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 631/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 632/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0081\n",
      "Epoch 633/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 634/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 635/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 636/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 637/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 638/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 639/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 640/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0082\n",
      "Epoch 641/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0081\n",
      "Epoch 642/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 643/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 644/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 645/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 646/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 647/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 648/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 649/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 650/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0082\n",
      "Epoch 651/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 652/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 653/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0081\n",
      "Epoch 654/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0081\n",
      "Epoch 655/1000\n",
      "1512/1512 [==============================] - 0s 11us/sample - loss: 0.0081\n",
      "Epoch 656/1000\n",
      "1512/1512 [==============================] - 0s 16us/sample - loss: 0.0081\n",
      "Epoch 657/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 658/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 659/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 660/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 661/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0082\n",
      "Epoch 662/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0081\n",
      "Epoch 663/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0081\n",
      "Epoch 664/1000\n",
      "1512/1512 [==============================] - 0s 17us/sample - loss: 0.0081\n",
      "Epoch 665/1000\n",
      "1512/1512 [==============================] - 0s 16us/sample - loss: 0.0081\n",
      "Epoch 666/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 667/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 668/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 669/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 670/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 671/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 672/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 673/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0081\n",
      "Epoch 674/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 675/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 676/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 677/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 678/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 679/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0081\n",
      "Epoch 680/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 681/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0081\n",
      "Epoch 682/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 683/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 684/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 685/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 686/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0081\n",
      "Epoch 687/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0081\n",
      "Epoch 688/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0081\n",
      "Epoch 689/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0081\n",
      "Epoch 690/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0081\n",
      "Epoch 691/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0081\n",
      "Epoch 692/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 693/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 694/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 695/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 696/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 697/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 698/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 699/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 700/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 701/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 702/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0081\n",
      "Epoch 703/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 704/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 705/1000\n",
      "1512/1512 [==============================] - 0s 15us/sample - loss: 0.0081\n",
      "Epoch 706/1000\n",
      "1512/1512 [==============================] - 0s 14us/sample - loss: 0.0081\n",
      "Epoch 707/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0081\n",
      "Epoch 708/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 709/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 710/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0081\n",
      "Epoch 711/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 712/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 713/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 714/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 715/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 716/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 717/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0081\n",
      "Epoch 718/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0080\n",
      "Epoch 719/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 720/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 721/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0080\n",
      "Epoch 722/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0081\n",
      "Epoch 723/1000\n",
      "1512/1512 [==============================] - 0s 15us/sample - loss: 0.0081\n",
      "Epoch 724/1000\n",
      "1512/1512 [==============================] - 0s 13us/sample - loss: 0.0081\n",
      "Epoch 725/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 726/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 727/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 728/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 729/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 730/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 731/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 732/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 733/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0080\n",
      "Epoch 734/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 735/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 736/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 737/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 738/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 739/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0081\n",
      "Epoch 740/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0081\n",
      "Epoch 741/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0081\n",
      "Epoch 742/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 743/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 744/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0081\n",
      "Epoch 745/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 746/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0081\n",
      "Epoch 747/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 748/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0081\n",
      "Epoch 749/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0081\n",
      "Epoch 750/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 751/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 752/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0081\n",
      "Epoch 753/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 754/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 755/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0080\n",
      "Epoch 756/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 757/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 758/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 759/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 760/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 761/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 762/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0080\n",
      "Epoch 763/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 764/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0081\n",
      "Epoch 765/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 766/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 767/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 768/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0080\n",
      "Epoch 769/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 770/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 771/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 772/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0081\n",
      "Epoch 773/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 774/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 775/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 776/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0081\n",
      "Epoch 777/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 778/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 779/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 780/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0080\n",
      "Epoch 781/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 782/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 783/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 784/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 785/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0080\n",
      "Epoch 786/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 787/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 788/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 789/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 790/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 791/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 792/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 793/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0080\n",
      "Epoch 794/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 795/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 796/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0080\n",
      "Epoch 797/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 798/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 799/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 800/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 801/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 802/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 803/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 804/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 805/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 806/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 807/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0081\n",
      "Epoch 808/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0081\n",
      "Epoch 809/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 810/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 811/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0080\n",
      "Epoch 812/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 813/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 814/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 815/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 816/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0080\n",
      "Epoch 817/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 818/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 819/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 820/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 821/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0080\n",
      "Epoch 822/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 823/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0080\n",
      "Epoch 824/1000\n",
      "1512/1512 [==============================] - 0s 14us/sample - loss: 0.0080\n",
      "Epoch 825/1000\n",
      "1512/1512 [==============================] - 0s 15us/sample - loss: 0.0080\n",
      "Epoch 826/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0080\n",
      "Epoch 827/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 828/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 829/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 830/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 831/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 832/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 833/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0080\n",
      "Epoch 834/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0080\n",
      "Epoch 835/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 836/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 837/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 838/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 839/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 840/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0080\n",
      "Epoch 841/1000\n",
      "1512/1512 [==============================] - 0s 17us/sample - loss: 0.0080\n",
      "Epoch 842/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 843/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 844/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 845/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 846/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 847/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 848/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 849/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 850/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 851/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 852/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 853/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 854/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0080\n",
      "Epoch 855/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0079\n",
      "Epoch 856/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0080\n",
      "Epoch 857/1000\n",
      "1512/1512 [==============================] - 0s 16us/sample - loss: 0.0080\n",
      "Epoch 858/1000\n",
      "1512/1512 [==============================] - 0s 10us/sample - loss: 0.0080\n",
      "Epoch 859/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 860/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0080\n",
      "Epoch 861/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0080\n",
      "Epoch 862/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 863/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 864/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 865/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 866/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 867/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 868/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 869/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 870/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 871/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 872/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 873/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 874/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 875/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0079\n",
      "Epoch 876/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 877/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0080\n",
      "Epoch 878/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0079\n",
      "Epoch 879/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0080\n",
      "Epoch 880/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0080\n",
      "Epoch 881/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 882/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0080\n",
      "Epoch 883/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 884/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 885/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 886/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 887/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 888/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 889/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 890/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0080\n",
      "Epoch 891/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0079\n",
      "Epoch 892/1000\n",
      "1512/1512 [==============================] - 0s 13us/sample - loss: 0.0079\n",
      "Epoch 893/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 894/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0079\n",
      "Epoch 895/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0079\n",
      "Epoch 896/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 897/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 898/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 899/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 900/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 901/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 902/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 903/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 904/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 905/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0080\n",
      "Epoch 906/1000\n",
      "1512/1512 [==============================] - 0s 17us/sample - loss: 0.0080\n",
      "Epoch 907/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0079\n",
      "Epoch 908/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 909/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0079\n",
      "Epoch 910/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0079\n",
      "Epoch 911/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 912/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0080\n",
      "Epoch 913/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 914/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0080\n",
      "Epoch 915/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 916/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0079\n",
      "Epoch 917/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0079\n",
      "Epoch 918/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0079\n",
      "Epoch 919/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0079\n",
      "Epoch 920/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 921/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0079\n",
      "Epoch 922/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0080\n",
      "Epoch 923/1000\n",
      "1512/1512 [==============================] - 0s 25us/sample - loss: 0.0079\n",
      "Epoch 924/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0080\n",
      "Epoch 925/1000\n",
      "1512/1512 [==============================] - 0s 15us/sample - loss: 0.0080\n",
      "Epoch 926/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0080\n",
      "Epoch 927/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0080\n",
      "Epoch 928/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 929/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0080\n",
      "Epoch 930/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 931/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 932/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 933/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0079\n",
      "Epoch 934/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0079\n",
      "Epoch 935/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0079\n",
      "Epoch 936/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0079\n",
      "Epoch 937/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0079\n",
      "Epoch 938/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 939/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0080\n",
      "Epoch 940/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0079\n",
      "Epoch 941/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0080\n",
      "Epoch 942/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0079\n",
      "Epoch 943/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0079\n",
      "Epoch 944/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0079\n",
      "Epoch 945/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0079\n",
      "Epoch 946/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0079\n",
      "Epoch 947/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 948/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0079\n",
      "Epoch 949/1000\n",
      "1512/1512 [==============================] - 0s 14us/sample - loss: 0.0079\n",
      "Epoch 950/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0079\n",
      "Epoch 951/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 952/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0079\n",
      "Epoch 953/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0079\n",
      "Epoch 954/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0079\n",
      "Epoch 955/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0079\n",
      "Epoch 956/1000\n",
      "1512/1512 [==============================] - 0s 24us/sample - loss: 0.0079\n",
      "Epoch 957/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0079\n",
      "Epoch 958/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0080\n",
      "Epoch 959/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0079\n",
      "Epoch 960/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0079\n",
      "Epoch 961/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0079\n",
      "Epoch 962/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 963/1000\n",
      "1512/1512 [==============================] - 0s 19us/sample - loss: 0.0079\n",
      "Epoch 964/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0079\n",
      "Epoch 965/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0079\n",
      "Epoch 966/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 967/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 968/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 969/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 970/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 971/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0080\n",
      "Epoch 972/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 973/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 974/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 975/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0079\n",
      "Epoch 976/1000\n",
      "1512/1512 [==============================] - 0s 23us/sample - loss: 0.0080\n",
      "Epoch 977/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0079\n",
      "Epoch 978/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 979/1000\n",
      "1512/1512 [==============================] - 0s 16us/sample - loss: 0.0080\n",
      "Epoch 980/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0079\n",
      "Epoch 981/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0079\n",
      "Epoch 982/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0079\n",
      "Epoch 983/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0079\n",
      "Epoch 984/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0079\n",
      "Epoch 985/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0079\n",
      "Epoch 986/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0079\n",
      "Epoch 987/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0079\n",
      "Epoch 988/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0079\n",
      "Epoch 989/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 990/1000\n",
      "1512/1512 [==============================] - 0s 22us/sample - loss: 0.0080\n",
      "Epoch 991/1000\n",
      "1512/1512 [==============================] - 0s 18us/sample - loss: 0.0079\n",
      "Epoch 992/1000\n",
      "1512/1512 [==============================] - 0s 11us/sample - loss: 0.0079\n",
      "Epoch 993/1000\n",
      "1512/1512 [==============================] - 0s 15us/sample - loss: 0.0079\n",
      "Epoch 994/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0080\n",
      "Epoch 995/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0079\n",
      "Epoch 996/1000\n",
      "1512/1512 [==============================] - ETA: 0s - loss: 0.006 - 0s 22us/sample - loss: 0.0079\n",
      "Epoch 997/1000\n",
      "1512/1512 [==============================] - 0s 20us/sample - loss: 0.0079\n",
      "Epoch 998/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0079\n",
      "Epoch 1000/1000\n",
      "1512/1512 [==============================] - 0s 21us/sample - loss: 0.0079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ee64b7b630>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 1: build the model\n",
    "model1 = Sequential()\n",
    "#input layer\n",
    "model1.add(Dense(10, input_dim = 14, activation = 'relu'))\n",
    "#hidden layer\n",
    "model1.add(Dense(5, activation = 'relu'))\n",
    "#output layer\n",
    "model1.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "# step 2: build the computational graph - compile\n",
    "model1.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "\n",
    "# step 3: train the model\n",
    "model1.fit(X_train_nn, y_train, epochs = 1000, batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512/1512 [==============================] - 0s 81us/sample - loss: 0.0079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0078816687707942"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_train_nn, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 0s 36us/sample - loss: 0.0141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.014101203910932683"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test_nn, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
